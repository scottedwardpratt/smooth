\documentclass[UserManual.tex]{subfiles}
\begin{document}
\section{Tuning the Emulator}\label{sec:emulator}

\subsection{Overview}

Smooth emulator finds an optimum set of Taylor expansion coefficients that reproduce a set of observables at a set of training points. The process of finding those coefficients is referred to as ``tuning''. For a given observable, a particular sample set of coefficients gives the following emulated function:
\begin{align*}\eqnumber
Y(\vec{\theta})&=\sum_{\vec{n}}d(\vec{n})A_{\vec{n}}
\left(\frac{\theta_1}{\Lambda}\right)^{n_1}
\left(\frac{\theta_2}{\Lambda}\right)^{n_2}
\cdots.
\end{align*}
Here, $\theta_1\theta_2\cdots$ represent the original model parameters, $\vec{X}$, but are scaled. If their initial prior is uniform, they are scaled so that their priors range from -1 to +1, and if they have  Gaussian priors, they are scaled so that their variance is one third. The degeneracy factor, $d(\vec{n})$ is the number of different ways to sum the powers $n_i$ to a given rank,
\begin{align*}\eqnumber
d(\vec{n})=\sqrt{\frac{(n_1+n_2+\cdots)!}{n_1!n_2!\cdots}}.
\end{align*}
As described in Sec. \ref{sec:theory}, the coefficients are chosen weighted by the distribution,
\begin{eqnarray}\label{eq:EmuWeight}
P(\vec{A})=\prod_n\frac{1}{\sqrt{2\pi\sigma_A^2}}e^{-A_n^2/2\sigma_A^2},
\end{eqnarray}
where $\sigma_A$ is varied to maximize the overall probability given the constraint of reproducing the training points. Given training points {\it Smooth Emulator} finds optimum values of $\sigma_A$ and $\Lambda$. From \href{./smoothdraft.pdf}{{\tt smoothdraft.pdf}} one can see that the choice of the two hyper-parameters for very similar functions can vary substantially, because there is weak sensitivity to the ratio $\Lambda/\sigma_A$, and strong sensitivity to the product $\sigma_A\Lambda$. Nonetheless, the emulator does a good job in predicting its uncertainty. Due to the kernel trick {\it Smooth Emulator} needn't calculate all the coefficients, even though there are expressions for them. Instead the resulting form for the optimum emulation is
\begin{eqnarray}
Y_{\rm opt}(\vec{\theta})&=&\sum_{ab}C_0(\vec{\theta},\vec{\theta}_a)B^{-1}_{ab}y_b,\\
\nonumber
B_{ab}&=&C_0(\vec{\theta}_a,\vec{\theta}_b)+\alpha^2\delta_{ab},\\
\nonumber
C_0(\vec{\theta}_1,\vec{\theta}_2)&=&e^{-|\vec{\theta}_1-\vec{\theta}_2|^2/2\Lambda^2}.
\end{eqnarray}
Closed form for the uncertainties, as provided in \href{./smoothdraft.pdf}{{\tt smoothdraft.pdf}}, are also calculated by {\it Smooth Emulator} software. Here $\alpha$ represents an estimate of the point-by-point uncertainty as a fraction of $\alpha$. If one thinks the model calculations have an uncertainty that due to sampling or noise varies by an amount $\sigma_{\rm noise}$, and if one believes the characteristic strength of $Y$ is $\sigma_A$, one chooses $\alpha=\sigma_{\rm noise}/\sigma_A$. For example, if the full-model uses some sampling algorithm that has a 1\% uncertainty, one would choose $\alpha=0.01$. More discussion is provided in Sec. \ref{sec:theory}.   

The executables based on {\it Smooth Emulator} are located in the User's {\tt \$\{SMOOTH\_LOCAL\}/bin} directory. Examples of such executables are {\tt smoothy\_tune} or {\tt smoothy\_calcobs}. These functions must be executed from within the User's analysis directory. In the following subsections, we first review the format for each of the required input files, then describe how to run {\it Smooth Emulator}, how its output is stored.


\subsection{Preparing Files for {\it Smooth Emulator}}

Before training the emulator, one must first run the full model at a given set of training points. In addition to an options file (described in the next sub-section), the User must provide the following:


\begin{enumerate}\itemsep=0pt
\item A file listing the names of observables. This file is named\\{\tt smooth\_data/Info/observable\_info.txt}, where the path is relative to the analysis directory. The file format is:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   observable_name_1   ALPHA_1
   observable_name_2   ALPHA_1
   .
   observable_name_n   ALPHA_N
\end{Verbatim}
}\vspace*{-8pt}
The observable names should be simple strings, without spaces. Here, the values of {\tt ALPHA\_i} represent the point-by-point uncertainties inherent to the full-model calculations. If there is no such uncertainty, i.e. if you reran the full model with the same model parameters, you would always get the exact same value, then the values for {\tt ALPHA\_i} should be zero.

\item A file listing the names of the model parameters and their priors. This file is \sloppypar{\tt smooth\_data/Info/prior\_info.txt}. The file format is:\\
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   parameter_name_1  prior_type_1 xmin_1/centroid_1  xmax_1/Rgauss_1  ss_1
   parameter_name_2  prior_type_2 xmin_2/centroid_2  xmin_2/Rgauss_2  ss_2
   .
   parameter_name_N  prior_type_N xmin_N/centroid_N  xmin_N/Rgauss_N  ss_N
\end{Verbatim}
}\vspace*{-8pt}
Again, the parameter names should be simple strings without spaces. The {\tt prior\_type\_I} entries are character strings, either {\tt uniform} or {\tt gaussian}. If the prior type is {\tt uniform}, {\tt xmin\_I} and {\tt xmax\_I} represent the endpoints of the uniform prior. If the prior type is {\tt gaussian}, the prior is assumed to have a Gaussian form, the two values set the centroid and widths of the Gaussian priors. The last column is the sensitivity scale. If all model parameters are expected to provide equal variance, all the {\tt ss\_I} variables should unity. If some model parameters are expected to cause less variance, then they should be set to some fraction of unity. In practice, this lowers the relative expectation of how higher order terms in the Taylor contribute relative to lower-order terms for these model parameters.

\item At each training point the User must provide a list of the model-parameter values, $\vec{x}$ and the values of each observable as calculated by the full model at $\vec{x}$. The values of $\vec{x}$ at each point can be generated by {\tt trainingpoint\_optimizer}, as described in Sec. \ref{sec:tpo}, or they can be entered by hand. It is up to the User to run the full model at each training point to generate the observables.

The default location for files containing this information is the directory {\tt smooth\_data/FullModelRuns}, though that location can be changed in the options file described below. For each training point, the training-point and observable information is stored in a separate directory. If there are 100 training points, the directories would be {\tt smooth\_data/FullModelRuns/run0/}, {\tt smooth\_data/FullModelRuns/run0/}, $\cdots$, {\tt smooth\_data/FullModelRuns/run99/}.

Each directory, {\tt runI}, must contain two files, {\tt runI/model\_parameters.txt} and {\tt runI/obs.txt}. The file {\tt model\_parameters.txt} has the format:\\ 
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
parameter_name_1 x1  
parameter_name_2 x2  
.
\end{Verbatim}
}\vspace*{-8pt}
The model-parameter names must be identical to those listed in {\tt smooth\_data/Info/prior\_info.txt}, and the values of those parameters are {\tt x1}$\cdots$.

After running the full model, the User creates the files {\tt runI/obs.txt} in the following format. \\
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
observable_name_1 y1 
observable_name_1 y2
.
\end{Verbatim}
}\vspace*{-8pt}

\end{enumerate}

\subsection{{\it Smooth Emulator} Options}

{\it Smooth Emulator} requires a file describing the options,
\sloppypar{\tt \$\{MY\_ANALYSIS\}/smooth\_data/Options/emulator\_options.txt}. The ascii file is simply a list of option names followed by values. Here is an example of such a file.
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
# Location of output, comment out for interactive running
  # LogFileName smoothlog.txt
  SmoothEmulator_FixLambda false // If false will adjust optimize LAMBDA (false is default)
  # Smoothness parameter to start maximizing procedure
  SmoothEmulator_LAMBDA 2.5    // If SmoothEmulator_FixLambda is true, this fixes LAMBDA
  #
  # Location of training data, default is smooth_data/FullModelRuns
  SmoothEmulator_FullModelRunsDirName smooth_data/FullModelRuns
  #
  # Choose which runs to use for training. Can be set to "all" or as list, e.g. 1-5,8-12,15,18
  SmoothEmulator_TrainingPts all
  #
  # Below only used for testing agains full model runs not used for training.
  # Default location of testing data is smooth_data/FullModelTestingRuns/
  SmoothEmulator_FullModelTestingRunsDirName smooth_data/FullModelTestingRuns
  #
  # List of points to be used for testing, all is default, can list, e.g. 1-5,8-12,15,18
  SmoothEmulator_TestingPts all
  #
  # When calculating uncertainty, include(or not) the contribution from Lambda varying
  SmoothEmulator_INCLUDE_LAMBDA_UNCERTAINTY true
  #
\end{Verbatim}
}\vspace*{-8pt}
Any line beginning with {\tt \#} is ignored.  If any of these lines are missing from the options file, {\it Smooth Emulator} will assign the default value. Here is a synopsis of the various options one can set.

\subsubsection{{\tt LogFileName}}
If this is commented out, as it is in the example above, {\it Smooth Emulator}'s main output will be directed to the screen and the program will run interactively. Otherwise, the output will be recorded in the specified file. Most often, one will wish the program to run interactively.

\subsubsection{{\tt SmoothEmulator\_FixLambda (default false)}}
Smooth Emulator will choose optimum values for the hyper-parameters $\Lambda$ and $\sigma_A$ based on the training data. But, if the User wishes to choose their own value of $\Lambda$, they can set {\tt SmoothEmulator\_FixLambda} to {\tt false}.

\subsubsection{{\tt SmoothEmulator\_LAMBDA (default 3.0)}}
If {\tt SmoothEmulator\_FixLambda} is set to {\tt true}, this sets the convergence parameter $\Lambda$.

\subsubsection{{\tt SmoothEmulator\_FullModelRunsDirName (default smooth\_data/FullModelRuns)}}
This is only relevant if {\tt SmoothEmulator\_TrainingFormat} is set to {\tt SMOOTH}. This identifies the location of the directory where the training data is stored. The various run directories, {\tt run0}, {\tt run1}, $\cdots$, are subdirectories of this directory, and each sub-directory stores the information defining the full-model run for a specific point in model-parameter space.

\subsubsection{{\tt SmoothEmulator\_TrainingPts (default all)}}
This is also only relevant if {\tt SmoothEmulator\_TrainingFormat} is set to {\tt SMOOTH}. If set to the default value, {\tt all}, all the full-model runs in the directory identified by {\tt SmoothEmulator\_FullModelRunsDirName} will be used to train the emulator. If one wishes to use some subset of the run directories, this should be a string featuring numbers, commas and dashes. For example, {\tt 0-3,9,12-14} uses the runs numbered 0,1,2,3,9,12,13,24.

\subsubsection{{\tt SmoothEmulator\_FullModelTestingRunsDirName (default smooth\_data/FullModelRuns)}}
This is only relevant if {\tt SmoothEmulator\_TrainingFormat} is set to {\tt SMOOTH}. This identifies the directory where the testing data is stored. The various run directories, {\tt run0}, {\tt run1}, $\cdots$, are subdirectories of this directory, and each sub-directory stores the information defining the full-model run for a specific point in model-parameter space.

\subsubsection{{\tt SmoothEmulator\_TestingPts (default all)}}
This is also only relevant if {\tt SmoothEmulator\_TrainingFormat} is set to {\tt SMOOTH}. If set to the default value, {\tt all}, all the full-model runs in the directory identified by {\tt SmoothEmulator\_FullModelRunsDirName} will be used to train the emulator. If one wishes to use some subset of the run directories, this should be a string featuring numbers, commas and dashes. For example, {\tt 0-3,9,12-14} uses the runs numbered 0,1,2,3,9,12,13,24.

\subsection{Running {\it Smooth Emulator} Programs}

The source code for several {\it Smooth Emulator} main programs can be found in the \\{\tt \$\{SMOOTH\_LOCAL\}/software/main\_programs/} directory. They are separated from the bulk of the software, which is in the {\tt \$\{bandframework\}/SmoothEmulator/software/} directory. The main programs are designed so that the User can easily copy and edit them to create versions that might be more appropriate to the User's specific needs. When compiled, from the {\tt \$\{SMOOTH\_LOCAL\}/software/} directory, the executables appear in the {\tt \$\{SMOOTH\_LOCAL\}/bin/} directory. If the User wishes to make new executables, it is perhaps easiest to edit and rename the existing programs in the {\tt \$\{SMOOTH\_LOCAL\}/software/main\_programs/} directory and then add the appropriate line to the {\tt \$\{SMOOTH\_LOCAL\}/software/CMakeLists.txt} file. After briefly discussing how to run the codes, a review of the four codes that use the emulation functionality is provided. The source code for these four codes is provided here with the purpose of showing the User how they might use these codes as bases for designing and coding their own main programs.

From within the {\tt \$\{SMOOTH\_LOCAL\}/software/} directory, one can compile the programs with the command:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 $\{SMOOTH_LOCAL\}/software% cmake .
 $\{SMOOTH_LOCAL\}/software% make
\end{Verbatim}
}\vspace*{-8pt}

The executables should now appear in the {\tt \$\{SMOOTH\_LOCAL\}/bin/} directory. If one enters {\tt make} {\it program name} only that program  will be compiled. One can peruse the source codes in {\tt \$\{SMOOTH\_LOCAL\}/software/MainPrograms}. Assuming the directory {\tt \$\{SMOOTH\_LOCAL\}/bin/} has been added to the User's path, the User may switch to the User's analysis directory, and enter the program name, e.g.
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
  $\{MY_ANALYSIS\}% smoothy_testattrainingpts
\end{Verbatim}
}\vspace*{-8pt}
There are four main programs provided in the distribution which read in the training data, train an emulator and perform an operation. The four executables are:
\subsubsection{{\tt smoothy\_testattrainingpts}}
This program builds and tunes the emulator, then compares the emulator predictions to the training values. If the point-by-point noise parameter, $\alpha$, is set to zero the emulator should precisely match the training values. The output of the program lists the predictions for each observables. For example, the output might look something like this:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
% \textcolor{darkred}{smoothy_testattrainingpts}
 ------ first_observable_name -------------
 ---- Lambda=3.070954, SigmaA=93.242332
 - itrain --- Y_full     Y_emulator    Sigma_emulator
  0 Y[0]= 4.385e+01 =?  4.385e+01  +/-  2.41322e-05
  1 Y[0]= 9.320e+01 =?  9.320e+01  +/-  1.53834e-05
  2 Y[0]= 4.381e+01 =?  4.381e+01  +/-  2.57861e-05
  .
\end{Verbatim}
}\vspace*{-8pt}

The first column denotes the specific training point, the second and third columns represents the observable as calculated by the full model and emulator, with the emulator's uncertainty provided in the last column. After printing the information for the first observable, the program then provides the comparison for the subsequent observables.

The main program, {\tt \$\{SMOOTH\_LOCAL\}/software/main\_programs/smoothy\_testattrainingpts\_main.cc}, for this executable is rather short and simple:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   master.TestAtTrainingPts();
   return 0;
\}
\end{Verbatim}
}\vspace*{-8pt}
The functionality is mainly accessed through the {\tt CSmoothMaster} object. The constructor reads in the information and options files, plus the training data (and testing data if it exists). The tuning command, {\tt master.TuneAllY()}, finds optimum values for the two hyper-parameters, plus stores a few arrays for quicker calculation.

\subsubsection{{\tt smoothy\_testvsfullmodel}}
As the name suggests, this program compares the emulated values to full-model calculations, but instead of comparing to values calculated at training points, it compares to full-model calculations at training points not used to train the data.
For each observable, the output describes the accuracy averaged over the testing points. An example output is:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
% \textcolor{darkred}{smoothy_testvsfullmodel}
 iY=0: <(Y-Yreal)^2>/SigmaY^2_emulator=1.313787
 percent < 1 sigma = 75.000000
 iY=1: <(Y-Yreal)^2>/SigmaY^2_emulator=1.304912
 percent < 1 sigma = 69.642857
 .
\end{Verbatim}
}\vspace*{-8pt}
For the first observable, this shows that the average (over the testing points) difference squared between the emulator and full model for the first observable was 1.314 times the stated uncertainty and that 75\% of the emulator predictions were within the stated emulator uncertainty. The User can find a training-point-by-training-point comparison in the file {\tt smooth\_data/output\_stuff/fullmodel\_testdata/YvsY\_}{\it observable\_name}{\tt.txt}.

The source code is also brief.
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   master.TestVsFullModel();
   return 0;
\}
\end{Verbatim}
}\vspace*{-8pt}

\subsubsection{{\tt smoothy\_calcobs}}
This program prompts the User for the model parameters, then prints out the predictions for all the observables. The source code, {\tt \$\{SMOOTH\_LOCAL\}/software/main\_programs/smoothy\_calcobs\_main.cc}, provides an example how the User might write a program to access more specific output:
\vspace*{-8pt}{\tt
\begin{Verbatim}[commandchars=\\\{\}]
int main()\{
   NBandSmooth::CSmoothMaster master;
   //master.ReadCoefficients();
   master.TuneAllY();
   
   //Create model parameter object to store information about a single set of model parameters
   NBandSmooth::CModelParameters *modpars=new NBandSmooth::CModelParameters(); // object describes single point
   modpars->priorinfo=master.priorinfo; // priorinfo stores the information about the priors
   // Print out the prior information
   master.priorinfo->PrintInfo();
   
   // Prompt user for model parameter values and enter them into the modpars object
   vector<double> X(modpars->NModelPars);
   for(unsigned int ipar=0;ipar<modpars->NModelPars;ipar++){
      cout << "Enter value for " << master.priorinfo->GetName(ipar) << ":\\n";
      cin >> X[ipar];
   }
   modpars->SetX(X);
   
   //  Calc Observables
   NBandSmooth::CObservableInfo *obsinfo=master.observableinfo;
   vector<double> Y(obsinfo->NObservables); // observable values
   vector<double> SigmaY(obsinfo->NObservables); // uncertainties
   master.GetAllY(modpars,Y,SigmaY); // Calculates Y and SigmaY in terms of the model parameters
   cout << "---- EMULATED OBSERVABLES ------\\n";
   for(unsigned int iY=0;iY<obsinfo->NObservables;iY++){
      cout << obsinfo->GetName(iY) << " = " << Y[iY] << " +/- " << SigmaY[iY] << endl;
   }
   
   return 0;
\}
\end{Verbatim}
}\vspace*{-8pt}
Again, this source code illustrates how the User can access the functionality of the emulator through member functions of the {\tt CSmoothMaster} class.

\subsubsection{{\tt smoothy\_mcmc}}
As the title suggests, this program runs the MCMC exploration of model-parameter space using the emulator. The source code for the included main program, {\tt \$\{SMOOTH\_LOCAL\}/software/main\_programs/smoothy\_mcmc\_main.cc}, uses the functionality of both the {\tt CSmoothMaster} class and the {\tt CMCMC} class. The MCMC codes are discussed in detail in Sec. \ref{sec:mcmc}.

\subsection{Functions and Methods of the {\tt CSmoothMaster} and Related Classes}
{\it Smooth Emulator} was designed so that the User can write their own main programs and access the functionality mainly through references to the {\tt CSmoothMaster} object. Additionally, the User might find it useful to access the {\tt CModelParameters}, {\tt CparameterMap}, {\tt CPriorInfo}, and {\tt CObservableInfo} objects. Here is a compendium of calls to the {\tt CSmoothMaster}:

\begin{itemize}\itemsep=0pt
\item {\tt CSmoothMaster()}\\
When the object is instantiated, the object will read the information, training and testing data.
\item {\tt void ReadTrainingInfo()}\\
This reads the training point information to be used for tuning. It is done automatically when creating the {\tt CSmoothMaster} object.
\item {\tt void TuneAllY()}\\ //
Tune all observables, $Y$.
\item {\tt void TuneY(string obsname)}\\
Tunes one observable, by observable name.
\item {\tt void TuneY(unsigned int iY)}\\
Tune one observable, referenced by index.
\item {\tt void CalcAllY(CModelParameters *modelpars,vector<double> \&Y,\\vector<double> \&SigmaY\_emulator)}\\
Calculates all observables. CModelParameters object stores information about a single point in model-parameter space. Object described further below.
\item {\tt void CalcY(unsigned int iY,CModelParameters *modelpars,double \&Y,\\double \&SigmaY\_emulator)}\\
Calculates observable referenced by index.
\item {\tt void CalcY(string obsname,CModelParameters *modelpars,double \&Y,\\double \&SigmaY\_emulator)}\\
Calculates observable referenced by observable name.
\item {\tt void CalcAllYdYdTheta(CModelParameters *modelpars,vector<double> \&Y,\\
vector<double> \&SigmaY\_emulator,vector<vector<double>> \&dYdTheta)}\\
Also calculates derivatives w.r.t. $\vec{\theta}$. Useful for some Markov chain searches in parameter space, e.g. Langevin approaches.
\item {\tt void CalcYdYdTheta(string obsname,CModelParameters *modelpars,double \&Y,\\double \&SigmaY\_emulator,vector<double> \&dYdTheta)}\\
Same, but for one observable referenced by observable name.
\item {\tt void CalcYdYdTheta(unsigned int iY,CModelParameters *modelpars,double \&Y,\\double \&SigmaY\_emulator,vector<double> \&dYdTheta)}\\
Same, but by index.
\item {\tt void CalcAllYOnly(CModelParameters *modelpars,vector<double> \&Y)} and {\tt CalcAllYOnly(vector<double> \&theta,vector<double> \&Y)} calculates the observable but with the uncertainty.
\item {\tt double GetUncertainty(string obsname,vector<double> \&theta)} and {\tt GetUncertainty(unsigned int iY,vector<double> \&theta)} returns the emulator uncertainty only, for a specific observable.		
\item {\tt void CalcAllLogP()}\\
Prints technical information the User may find helpful in evaluating whether the choice of $\Lambda$ is reasonable. For each observable, it calculates the ratio of the r.m.s. coefficients of rank-two to those of rank-one. One would roughly expect the ratio to be unity if $\Lambda$ is appropriate, but from testing the measure is so noisy that it is not useful on a observable-by-observable basis. It also calculates the probability for the optimum coefficient set. This would be maximized for best choices of $\Lambda$, but again is highly sensitive to fluctuations. Thus, this information is not recommended for actual tuning $\Lambda$.
\item {\tt void TestAtTrainingPts()}\\
Compares emulator predictions to full model calculations at training points. Observables should match and uncertainties should vanish.
\item {\tt void TestAtTrainingPts(string obsname)}\\
Same but for a single observable referenced by observable name.
\item {\tt void TestAtTrainingPts(unsigned int iY)}\\
Same but for a single observable referenced by index.
\item {\tt void TestVsFullModel()}\\
This is useful for comparing emulator to model evaluated at points not used for training. You can set the emulator parameter {\tt SmoothEmulator\_TestingPts} in the same manner as was done for the emulator parameter {\tt SmoothEmulator\_TrainingPts}. It will compare the emulator to the results in the run directories specified here. Usually, one wishes to compare at points not used for training. Fore example, if there were 100 run directories, one might set
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
SmoothEmulator_TrainingPts 0-89
SmoothEmulator_TestingPts 90-99
\end{Verbatim}
}\vspace*{-8pt}
to train the emulator with the first 90 points and test it at the last 10 points. Tests for each observable are stored in a directory {\tt fullmodel\_testdata/}.

\item {\tt void WriteCoefficientsAllY()}\\
Writes the Taylor coefficients for all observables. Because tuning is so fast, the User can usually avoid reading and writing coefficients, and instead simply re-perform the tuning. 
\item {\tt void WriteCoefficients(string obsname)}\\
Writes only those for one observable referenced by observable name.
\item {\tt void WriteCoefficients(unsigned int iY)}\\
Writes only for one observable reference by index.
\item {\tt void ReadCoefficientsAllY()}\\
Reads all Taylor coefficients from file.
\item {\tt void ReadCoefficients(string obsname)}\\
Reads Taylor coefficients for one observable referenced by observable name.
\item {\tt void ReadCoefficients(unsigned int iY)}\\
Reads Taylor coefficients for one observable referenced by observable index.
\end{itemize}
It would probably be useful to view the header file for the {\tt master} class, {\tt \${SMOOTH\_HOME}/software/include/msu\_smooth/master.h}.

\subsection{Other Potentially Useful {\it Smooth Emulator Objects}}

The four programs described above access the functionality through the {\tt CSmoothMaster} object. However, within the main program one may also wish to apply or access other objects with the {\it Smooth Emulator} framework. Their functionalities are described here:
\begin{itemize}\itemsep=0pt
\item {\tt CparameterMap}\\
This object stores the emulator parameters described above. It is a simple inheritization of a map, linking string labels to values of various types. The object can read a parameter list from a file, e.g.
\vspace*{-8pt}{\tt
\begin{Verbatim}[commandchars=\\\{\}]
 CparameterMap parmap;
 parmap.ReadParsFromFile ("smooth_data/smooth_parameters/emulator_parameters.txt")
\end{Verbatim}
}\vspace*{-8pt}
The argument can be either a C++ string or a character array. The CSmoothMaster constructor takes a pointer to a CparameterMap object as a argument. If one wishes to print the parameters, the function is {\tt parmap.PrintPars()}. To set a parameter within a program, {\tt parmap.set(string,value)}, where {\tt value} can be any of several types, e.g. bool, double, an integer, long long integer, string, $\cdots$. To retrieve a value from the map, the commands are {\tt getB, getI, getLongI, getS, getD}, $\cdots$, for {\tt bool, int, long long int} $\cdots$ types. For example, one can access options from the {\tt CSmoothMaster} object via
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 double Lambda=master->parmap->getD("SmoothEmulator_LAMBDA",2.5);
\end{Verbatim}
}\vspace*{-8pt}
If the map did not include {\tt SmoothEmulator\_LAMBDA}, it would return a default value of 2.5.

More detailed information about the {\tt CparameterMap} class is provided in Sec. \ref{sec:parametermap}.

\item {\tt CPriorInfo}\\
This object stores information about the prior. The {\tt CSmoothMaster} object includes such an object, and automatically, during its construction, the {\tt CSmoothMaster} object reads in the {\tt smooth\_data/Info/prior\_info.txt} file and creates the object. The functionalities of potential interest might be addressed from a main program via:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 smoothmaster.priorinfo.PrintInfo();  // prints out the parameter priors
 unsigned int ipar=smoothmaster.priorinfo.GetIPosition(PARAMETER_NAME);
   // finds position given name of parameter (string)
 string parname=smoothmaster.priorinfo.GetName(I);
   // finds name given position {\tt I} (unsigned int)
\end{Verbatim}
}\vspace*{-8pt}

\item {\tt CModelParameters}\\
This object stores the information describing a single point in the model-parameter space. It has two vectors storing the true $\vec{X}$ and the scaled $\vec{\theta}$ parameters. As a static variable, it stores a pointer to a {\tt CPriorInfo} object so that it can translate back and forth from $\vec{X}$ to $\vec{\theta}$. The functionalities are fairly easily seen from the definition of its members header file. The ones most likely to be accessed by the User are:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 vector<double> X;   // model parameters
 vector<double> Theta; // scaled model parameters
 void TranslateTheta_to_X();  // Given Theta, fill out X
 void TranslateX_to_Theta(); // Given X, fill out Theta
 void Print();    // Prints model parameters
 void Write(string filename);    // Writes model parameters
 void Copy(CModelParameters *mp);  // Copies from another object
 void SetTheta(vector<double> &theta);  // Sets model parameters from vector
 void SetX(vector<double> &X);  // Sets model parameters from vector
\end{Verbatim}
}\vspace*{-8pt}
The emulator software stores all model-parameter information in these objects. There is a {\tt CTrainingInfo} object within {\tt CSmoothMaster} that stores a vector of such objects.

\item {\tt CObservableInfo}\\
This object stores general information about all the observables, including their experimental value and experimental uncertainty. The object does not store observable information as calculated by the emulator. These objects are also fairly self-explanatory and the functionality can be ascertained by looking at some of the lines in the header file. 
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 unsigned int NObservables;
 vector<string> observable_name;
 vector<double> SigmaA0;
   // initial guess for spread of coefficients (only used for MC tuning methods)
 map<string,unsigned int> name_map;
 unsigned int GetIPosition(string obsname);
   // finds position given name of observable
 string GetName(unsigned int iposition);
   // finds name give position
 void ReadObservableInfo(string filename);
   // reads information about observable, either from
   //smooth\_data/Info/observable_info.txt or smooth\_data/Info/pca_info.txt 
 void ReadExperimentalInfo(string filename);
   // reads experimental measurement and uncertainty (used in MCMC)
 vector<double> YExp,SigmaExp;
   // experimental measurement information
 void PrintInfo();
\end{Verbatim}
}\vspace*{-8pt}

There is such an object in the {\tt CSmoothMaster} class. For example, to print the information about the observables from a main program, one would include the line:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 {\tt master->observableinfo->PrintInfo();}
\end{Verbatim}
}\vspace*{-8pt}

\end{itemize}

\end{document}
