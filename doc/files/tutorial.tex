\documentclass[UserManual.tex]{subfiles}
\begin{document}
\section{Tutorial}\label{sec:tutorial}

\subsection{Overview}

Working through this section constitutes a tutorial, consisting of the following steps.
\begin{enumerate}[label=\arabic*.]\itemsep=0pt
\item Copy the required files from the template directory to the User's space, and compile the main programs.
\item Set up the fake information files describing the priors, observable names and experimental measurements.
\item Run {\tt trainingpoint\_optimizer} to generate the model-parameter values at which the full model will be trained.
\item Run a fake (for the purposes of this tutorial) full model to generate the observables for each of the full-model runs. This includes files both for tuning the emulator and also for testing the emulator.
\item Run a program {\tt smoothy\_testattrainingpts} which builds and trains an emulator and checks that it reproduces the training points.
\item Run a program {\tt smooth\_testvsfullmodel} which creates data files comparing emulator predictions to full-model runs at random points not used to train the emulator. Create a plot illustrating the comparison.
\item Run an MCMC program that produces a trace through model-parameter space that consistently represents the posterior probability by comparing emulator predictions to fake experimental data. Run Python plotting programs that read MCMC data and provide visual representations of the model-parameter-space posterior the observable-parameter resolving power.
\end{enumerate}
The text here includes a much-condensed version of what appears in previous sections of the manual.

\subsection{Setting up the Directory and Compiling the Main Programs}
First download the repository. If the User wishes to download it into their home directory, {\tt /Users/CarlosSmith/}, they need to open a command-line window and enter:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
/Users/CarlosSmith% \textcolor{darkred}{git clone https://github.com/bandframework/bandframework.git}
\end{Verbatim}
}\vspace*{-8pt}
The command line examples in this section assume that the prompt is writing down the current path followed by a percent sign.

After downloading the repository, copy the files to convenient places.
An analysis directory template is provided with the intention that the User will copy the directory to their own space, then use this as a foundation from which to embark on their own analysis. This template also provides the files for a tutorial. Assuming the User downloaded the repository to /Users/CarlosSmith/bandframework, the following commands copy the needed files to some more convenient locations.
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 ..% \textcolor{darkred}{cp -r /Users/CarlosSmith/bandframework/software/SmoothEmulator   /Users/CarlosSmith/SmoothHome}
 ..% \textcolor{darkred}{cp -r ${SMOOTH_HOME}/AnalysisTemplate /Users/CarlosSmith/MyAnalysis}
 ..% \textcolor{darkred}{cp -r ${SMOOTH_HOME}/LocalTemplate /Users/CarlosSmith/MyLocal}
\end{Verbatim}
}\vspace*{-8pt}
Here, {\tt ../SmoothHome}, {\tt ../MyAnalysis} and {\tt ../MyLocal} can be replaced by any directory name the User chooses. For the rest of the tutorial the following shorthand will be applied\\
\begin{tabular}{rl}\hline
{\tt \$\{SMOOTH\_HOME\}} & \parbox{5in}{~\\Location of Git Repository, e.g. \sloppypar{\tt /Users/CarlosSmith/bandframework/software/SmoothEmulator}\\}\\
{\tt \$\{MY\_LOCAL\}} & \parbox{5in}{Can be placed anywhere. Executables are store in \sloppypar{\tt \$\{MY\_LOCAL\}/bin} and main programs, and source codes for main\\ programs are found within {\tt \$\{MY\_LOCAL\}/software/main\_programs}\\}\\
{\tt \$\{MY\_ANALYSIS\}} & \parbox{5in}{Can be placed anywhere. Work spaces where parameter files, data, results and figures are created and stored. You may have several different such directories\\}\\
 \hline
\end{tabular}

You should be sure to have a C++ compiler that handles the C++-20 standard. You should also have cmake the Eigen linear algebra package installed. You should also need a Python distribution installed along with the matplotlib package. Next, to compile the programs
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
..% cd $\{SMOOTH_HOME\}/software
$\{SMOOTH_HOME\}/software% cmake .
$\{SMOOTH_HOME\}/software% make
$\{SMOOTH_HOME\}/software% cd $\{MY_LOCAL\}/software
$\{MY_LOCAL\}/software% cmake .
$\{MY_LOCAL\}/software% make
\end{Verbatim}
}\vspace*{0.05in}

You can now compile the main libraries
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   ..% \textcolor{darkred}{cd $\{SMOOTH_HOME\}/software}
   $\{SMOOTH_HOME\}/software% \textcolor{darkred}{cmake .}
   $\{SMOOTH_HOME\}/software% \textcolor{darkred}{make}
\end{Verbatim}
}\vspace*{-8pt}

and the main programs,
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   ..% \textcolor{darkred}{cd $\{MY_LOCAL\}/software}
   $\{MY_LOCAL\}/software% \textcolor{darkred}{cmake .}
   $\{MY_LOCAL\}/software% \textcolor{darkred}{make}
\end{Verbatim}
}\vspace*{-8pt}

This will compile all the main source programs in {\tt \$\{MY\_LOCAL\}/software/MainPrograms/} and two programs used to generate files for the tutorial in {\tt \$\{MY\_LOCAL\}/software/TutorialPrograms/}. The repository was organized to encourage Users to edit any files in {\tt \$\{MY\_LOCAL\}/}. If the User wishes to restore any original files, a copy can be found at {\tt \$\{SMOOTH\_HOME\}/}.

Several executables should now appear in {\tt \$\{MY\_LOCAL\}/bin/}: \sloppypar{\tt trainingpoint\_optimizer, smoothy\_testattrainingpts, smoothy\_testvsfullmodel, smoothy\_calcobs, smoothy\_mcm}, which all involve the emulator. Two other executables, {\tt fakefullmodel} and {\tt fakeinfo} are only used for the tutorial. You might find it convenient to add \sloppypar{\tt \$\{MY\_LOCAL\}/bin} to their path. The reason these are compiled in a space separate from the main libraries, is that you may well wish to create your own main programs. This arrangement allows you to compile your own versions, while leaving the bulk of the source code unchanged. 

\subsection{Creating the Necessary Info Files}
You will run software from the {\tt \$\{MY\_ANALYSIS\}/} directory. Before a User can run the {\it Smooth Emulator} executables they must create text files that describe the model-parameter priors and list the observable names. These three files need to be in the {\tt \$\{MY\_ANALYSIS\}/smooth\_data/Info/} directory. For your own project, you would likely create these files by hand, but, for the purpose of this tutorial you can create all three files by running the program,

\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   ..% \textcolor{darkred}{cd $\{MY_ANALYSIS\}}
   $\{MY_ANALYSIS\}% \textcolor{darkred}{$\{MY_LOCAL\}/bin/fakeinfo}
   \end{Verbatim}
}\vspace*{-8pt}

The first file, {\tt smooth\_data/Info/prior\_info.txt}, describes the model parameters and their priors. This file is For the purposes of this tutorial, we consider a model with six model parameters:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
# par_name dist_type  xmin/centroid xmax/width  SensitivityScale
   par0 gaussian 0 100    1.00000
   par1 uniform -100 100  1.00000
   par2 gaussian 0 100    1.00000
   par3 uniform -100 100  1.00000
   par4 gaussian 0 100    1.00000
   par5 uniform -100 100  1.00000
\end{Verbatim}
}\vspace*{-8pt}
Thus, the model has six parameters. The second entry in each line is either {\tt uniform} or {\tt gaussian}. If the entry is {\tt uniform}, the last two numbers represent the range of the uniform prior, $x_{\rm min}$ and $x_{\rm max}$. If the second entry is {\tt gaussian} the third entry represents the center of the Gaussian distribution and the fourth represents the width. The final column represents the sensitivity scale, which must be between zero and 1.0. For the most impactful parameters, this should be set to 1.0. If a parameter is expected to provide little variance compared to the most impactful parameters, this should be set to some fraction. Roughly, if a parameter is expected to provide half as much variance as the most important parameters, it should be set to 0.5. For a full model, the User would replace this file with one appropriate for their own model. This file is required for training-point optimization, for tuning, and for the MCMC programs.  

The second file is {\tt smooth\_data/Info/observable\_info.txt}. This describes output values from the model. In the template, the file describes, in this case, ten observables:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
# ObservableName   ALPHA
   obs0 0
   obs1 0
   obs2 0
   obs3 0
   obs4 0
   obs5 0
   obs6 0
   obs7 0
   obs8 0
   obs9 0
\end{Verbatim}
}\vspace*{-8pt}
The first entry in each line simply provides the names of the observable which will be processed in the Bayesian analysis.  The second entry describes the point-to-point noise is usedq by the emulator tuning programs. Here, {\tt ALPHA} is the noise as a fraction of the characteristic variation of the observable, $\sigma_Y$. Noise refers to variations of the model that would occur if the model were rerun with the same model parameters, which is typically due to some finite sampling inherent to the model, e.g. if the particle is calculating the average energy of particles using a simulation, and if a finite number of simulations and particles are sampled, the observable might vary from run to another. If one expects that random uncertainty to be 5\% of the variation of the observable throughout the model parameter space, then {\tt ALPHA} would be 0.05. {\it Smooth Emulator} software assumes that this noise is the same for all the full calculations of the same observable. I.e., if 20 training runs were performed at different points in model-parameter space, the software assumes that the {\tt ALPHA} was not much different at one training point than at another. If {\tt ALPHA} is set to zero, the emulator will exactly reproduce the observables from the full model when evaluated at the training points. If one performed training runs with simulations using grossly different numbers of events at one training point vs another, then this shortcoming could potentially be an issue. This file is required by both the tuning and MCMC programs.

The third, and final file, {\tt smooth\_data/Info/experimental\_info.txt}, describes the actual measurements and only comes into play at the time the MCMC is being performed. The file in the tutorial might look like this:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
obs0  57.840878  10.0 0.0
obs1  -85.613188  10.0 0.0
obs2  43.335184  10.0 0.0
obs3  40.159450  10.0 0.0
obs4  38.013337  10.0 0.0
obs5  64.492673  10.0 0.0
obs6  -195.300157  10.0 0.0
obs7  99.587427  10.0 0.0
obs8  7.963056  10.0 0.0
obs9  68.844147  10.0 0.0
\end{Verbatim}
}\vspace*{-8pt}
The names of the observables must match those listed in the {\tt observable\_info.txt} file. The second column is the value reported by the experiment and the third column is the reported uncertainty. The uncertainty cannot be set to zero. The last column represents the model's uncertainty due to missing physics, i.e. not the uncertainty due to noise in the calculation. The contribution from random noise is incorporated into the emulator uncertainty. The uncertainty due to missing physics can be thought of as the error, or deviation from a perfect measurement, one might expect if one used the precisely correct parameters. One can think of this as the systematic error of the theory on which the model is built. For the purpose of the MCMC, the three uncertainties, that of the emulator, that from the experiment, and the model's systematic theoretical error, are all added in quadrature to provide the uncertainty relevant for calculating the log-likelihood in the MCMC.

For a real project, you would need to edit the three files, probably typing the information all in by hand. 

\subsection{Selecting Training Points with {\tt trainingpoint\_optimizer}}

Before running {\tt trainingpoint\_optimizer} you should inspect or edit the options file, {\tt smooth\_data/Options/tpo\_options.txt}. A template for this file is provided:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
TPO_Method  MCQuadratic  # can be "MC", "MCSphere", "MCSimplex", "MCSimplexPlus1", "MCQuadratic", "MCSphereQuadratic"
TPO_NTrainingPts    0   # only relevant for OptimizeMethod="MCSphere" or "MC"
TPO_NMC  100000
TPO_ALPHA 0.01 # does not have to be the same value used to train emulator
TPO_Include_LAMBDA_Uncertainty true # dangerous to set this to false
TPO_FullModelRunsDirName  smooth_data/FullModelRuns
#TPO_ReadPoints 0,1,4-7,10,11-13,21
#TPO_FreezePoints 0,1,4-7,10,11-13,21
\end{Verbatim}
}\vspace*{-8pt}
Options are described in detail in Sec. \ref{sec:tpo}. For this case {\tt TPO\_Method} was set to {\tt MCQuadratic}, which sets the number of training points equal to the minimum number for constraining all the expansion coefficients up to 2nd order, which for 6 model parameters is 28. If you had set {\tt TPO\_Method} to {\tt MC}, then the number of training points would have been set by the {\tt TPO\_NTrainingPts} option. It is safer to set {\tt TPO\_ALPHA} to non-zero. Even if your analysis will have no point-by-point statistical uncertainty, the procedure will be more robust with the value of 0.01 as set above.

If you had some existing training points and wanted to keep those, while choosing additional one, you can uncomment the last two lines. The option {\tt TPO\_ReadPoints} will read the designated points in from file (the very place where you would write the new points) and use them as starting points. If the points are also designated by {\tt TPO\_FreezePoints}, then they will stay fixed throughout the search. For example, if you had points 0-9 already calculated and wanted to find the best positions for 10 more points, you would set {\tt TPO\_NMC}=20 and set both {\tt TPO\_ReadPoints} and {\tt TPO\_FreezePoints} to 0-9.

Now you can run {\tt trainingpoint\_optimizer}, which is meant to be run interactively. This will generate a list of coordinates in model-parameter space for each of $N_{\rm train}$ training points. Simply run the program by calling the command. 
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
${MY_ANALYSIS}% \textcolor{darkred}{${MY_LOCAL}/bin/trainingpoint_optimizer}
NTrainingpts=28, NMC=100000, LAMBDA=2.500000, ALPHA=0.010000
Optimize_MC: at beginning: bestSigma2=0.016793
+++ finished 1%, expected accuracy=0.0084093, success %=35.6, step size=0.0094491
+++ finished 2%, expected accuracy=0.007779, success %=11.6, step size=0.013928
 .
+++ finished 100%, expected accuracy=0.0072105, success %=23.1, step size=7.1374e-05
\end{Verbatim}
}\vspace*{-8pt}
Your output might vary a bit because the random seed for the MCMC search is initialized by the current time. 

The program writes information about the training points in the {\tt smooth\_data/FullModelRuns/} directory. Changing into that directory, there should now be 28 sub-directories, corresponding to the 28 training points: {\tt FullModelRuns/run0}, {\tt FullModelRuns/run1}, {\tt FullModelRuns/run2} $\cdots$. Each directory has one text file describing the training points. For example, the {\tt modelruns/run21/model\_parameters.txt} file might be 
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 par0 -145.307
 par1 -6.8244
 par2 -67.4252
 par3 62.3719
 par4 -85.451
 par5 -29.6548
\end{Verbatim}
}\vspace*{-8pt}
This describes the six model parameters, which will serve as the input for that model run. Given that the MCMC procedure was randomly seeded, the actual model parameters for the 21st point will vary. Even if one were to run with {\tt TPO\_NMC} set to infinity, and the points were in perfect position, the 28 points could be in different order.

In this example, {\tt trainingpoint\_optimizer} was run with {\tt TPO\_Method} set to {\tt MCQuadratic}, which automatically set the number of training points to 28 given that there were six model parameters and 28 points are required to fully constrain a quadratic fit. If the option had been set to {\tt MCSimplex}, 7 points would have been chosen, the minimum number to constrain a linear fit (If all the priors were Gaussian, this would result in a simplex arrangement). If {\tt TPO\_Method} had been set to {\tt MC}, {\tt trainingpoint\_optimizer} would have used the option {\tt TPO\_NTrainingPts} to set the number of training points. The full range of options is described in Sec. \ref{sec:tpo}.

\subsection{Running the Full Model}
Once the training points have been generated, you will need to run the full model at each training point. For the tutorial, a fake full model is provided. It reads the model-parameter values in each {\tt smooth\_data/modelruns/runI/model\_parameters.txt} file and writes the corresponding observables for each point in model-parameter space, {\tt I}, in the file {\tt smooth\_data/modelruns/runI/obs.txt}.

You need to run the program {\tt fakefullmodel}, which is meant to be run interactively. Running the model, 
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   $\{MY_ANALYSIS\}% \textcolor{darkred}{$\{MY_LOCAL\}/bin/fakefullmodel}
   NPars=6, NObs=10
   Creating Fake Model Data for 28 Training Pts
\end{Verbatim}
}\vspace*{-8pt}
The output simply shows the number of model parameters, observables, and training points. The number of model parameters was found by reading {\tt smooth\_data/Info/prior\_info.tt} and the number of training points was determined by counting the number of files in {\tt smooth\_data/FullModelRuns}. The fake model is built on a Taylor expansion with random coefficients, chosen to be consistent with the form assumed by the emulator. This form is built on the choices of $\Lambda=3.0$ and $\Sigma_A=100$, so when the model is emulated the extracted hyper parameters can be compared to those values. Each of the 10 observables is assigned a separate randomly chosen set of coefficients.

Inspecting one of the output files, {\tt smooth\_data/FullMode/run0/obs.txt},
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 obs0 77.444888
 obs1 -78.684124
 obs2 62.298517
 obs3 109.230134
 obs4 70.629874
 obs5 106.994538
 obs6 -196.814283
 obs7 9.158107
 obs8 -29.184781
 obs9 41.295872
\end{Verbatim}
}\vspace*{-8pt}
Again, your output will be different. The second column provides the value of the specified observable for the full model at that specific training point. Additionally, {\tt fakefullmodel} created a directory {\tt smooth\_data/FullModelTestingRuns/} which stores information about full-model runs at randomly chosen points in the model-parameter space. These points and their corresponding data are not used for tuning. This data will be used below to test the emulator. The User need not create such files for their project, unless they wish to have some separate runs just for testing. 

\subsection{Training and Emulator and Testing it at the Training Points}
Before building and tuning the emulator, the User needs to edit one additional file, the text file that sets numerous options for {\it Smooth Emulator}. This file is {\tt smooth\_data/Options/emulator\_options.txt}. For the template used in this tutorial, the contents of that file appear as
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 # Location of output, comment out for interactive running
  # LogFileName smoothlog.txt
  SmoothEmulator_FixLambda false // If false will adjust optimize LAMBDA (false is default)
  # Smoothness parameter to start maximizing procedure
  SmoothEmulator_LAMBDA 2.5    // If SmoothEmulator_FixLambda is true, this fixes LAMBDA
  #
  # Location of training data, default is smooth_data/FullModelRuns
  SmoothEmulator_FullModelRunsDirName smooth_data/FullModelRuns
  #
  # Choose which runs to use for training. Can be set to "all" or as list, e.g. 1-5,8-12,15,18
  SmoothEmulator_TrainingPts all
  #
  # Below only used for testing agains full model runs not used for training.
  # Default location of testing data is smooth_data/FullModelTestingRuns/
  SmoothEmulator_FullModelTestingRunsDirName smooth_data/FullModelTestingRuns
  #
  # List of points to be used for testing, all is default, can make list, e.g. 1-5,8-12,15,18
  SmoothEmulator_TestingPts all
  #
  # When calculating uncertainty, include(or not) the contribution from Lambda varying
  SmoothEmulator_INCLUDE_LAMBDA_UNCERTAINTY true
  #
\end{Verbatim}
}\vspace*{-8pt}
More options are described in detail in Sec. \ref{sec:emulator}.The options are mostly self-described by their names. To build an emulator the program needs to know the values of the observables as calculated by the full model at the training points. That is stored in the {\tt smooth\_data/FullModelRuns/} directory as described above. Files from a different directory can be used if the option {\tt SmoothEmulator\_FullModelRunsDirName} is set to something different. You can also choose which training points are used in the directory through the {\tt SmoothEmulator\_TrainingPts} option.

Here, you will run the program {\tt \$\{MY\_LOCAL\}/bin/smoothy\_testattrainingpts}. The corresponding source code for the first is {\tt \$\{MY\_LOCAL\}/software/MainPrograms/smoothy\_testattrainingpts\_main.cc},
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   master.TestAtTrainingPts();
   return 0;
\}
\end{Verbatim}
}\vspace*{-8pt}
The options are set and the training data is read in by calling the constructor. The {\tt master} object stores information for all the emulators, as there is one per each observable. As suggested by the name, {\tt TuneAllY()} builds and trains emulators for all the observables. The method {\tt TestAtTrainingPts()} prints out a comparison of the emulator values to those of the full model. Because the point-to-point noise ($\alpha$) was set to zero in {\tt smooth\_data/Info/observable\_info.txt}, the emulator should exactly reproduce the full-model calculations at each of the training points and for each of the observables. Further, the emulator uncertainty at the training points should be zero.

Running this code:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
$\{MY_ANALYSIS\}% \textcolor{darkred}{$\{MY_LOCAL\}/bin/smoothy_testattrainingpts}
----------- obs0 -------------
---- Lambda=2.907369, SigmaA=91.294879
- itrain --- Y_full     Y_emulator    Sigma_emulator
 0 Y[0]= 2.925e+01 =?  2.925e+01  +/-  1.73835e-05
 1 Y[0]= 6.220e+01 =?  6.220e+01  +/-  8.01037e-06
 2 Y[0]= 1.213e+02 =?  1.213e+02  +/-  1.11063e-05
  .
 27 Y[0]= 1.387e+02 =?  1.387e+02  +/-  1.33291e-05
----------- obs1 -------------
---- Lambda=2.396985, SigmaA=66.961947
- itrain --- Y_full     Y_emulator    Sigma_emulator
 0 Y[1]=-9.653e+01 =? -9.653e+01  +/-  1.17626e-05
  .
\end{Verbatim}
}\vspace*{-8pt}
The second and third columns should be very close to one another, and the fourth column (the emulator uncertainty) should be close to zero. Indeed this is the case, though the numerical accuracy of the linear algebra routines does result in a small non-zero uncertainty. This thus represents a test of the procedure. Each emulator also optimizes a choice for the two hyper-parameters, $\Lambda$ and $\sigma_A$. Given that the full model was created by a random Taylor expansion consistent with $\Lambda=3$ and $\sigma_A=100$, one would expect the system to choose them. But, given the very finite number of training points, there can be significant differences. By reading \href{smoothdraft.pdf}{\tt smoothdraft.pdf} one can see that although there is often a significant deviation of a given observable's extracted hyper parameters, if one averages over many observables the expected value is rather well reproduced.

\subsection{Testing the Emulator at Points Not Used for Training}
In this case you will run the program {\tt \$\{MY\_LOCAL\}/software/bin/smoothy\_testvsfullmodel}. In addition to building and training the emulator, exactly as was done above, this program reads information about runs not used in the testing. This was set in the options file by the {\tt SmoothEmulator\_FullModelTestingRunsDirName} and {\tt SmoothEmulator\_TestingPts} options. The source code for the main program, {\tt \$\{MY\_LOCAL\}/software/MainPrograms/smoothy\_testvsfullmodel.cc}, is again rather simple. 
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   master.TestVsFullModel();
   return 0;
\}
\end{Verbatim}
}\vspace*{-8pt}
The data for the full model was created by the {\tt fakefullmodel} program for 50 random points, and is found in {smooth\_data/FullModelTestingRuns}. Running the program,
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
$\{MY_ANALYSIS\}% \textcolor{darkred}{smoothy_testvsfullmodel}
iY=0: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.857423
percent < 1 sigma = 44.000000
iY=1: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=0.965030
percent < 1 sigma = 72.000000
iY=2: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.138670
percent < 1 sigma = 65.000000
iY=3: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=3.380905
percent < 1 sigma = 65.000000
iY=4: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.080057
percent < 1 sigma = 58.000000
iY=5: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=0.833119
percent < 1 sigma = 77.000000
iY=6: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.698096
percent < 1 sigma = 54.000000
iY=7: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.739706
percent < 1 sigma = 46.000000
iY=8: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.089194
percent < 1 sigma = 63.000000
iY=9: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=0.874994
percent < 1 sigma = 80.000000
\end{Verbatim}
}\vspace*{-8pt}
Your results should look similar in principle, but will vary in detail because different random points were chosen. You can now peruse the files in {\tt smooth\_data/output\_stuff/fullmodel\_testdata/} and see the comparison of the 50 emulator values to the values calculated by {\tt fakefullmodel}. 

You can view this comparison by applying a Python plotting program, {\tt \$\{MY\_ANALYSIS\}/figs/YvsY/YvsY.py}. This program uses the Python package Matplotlib. Before running the plotting program, one must first create two information files. The first is {\tt \$\{MY\_ANALYSIS\}/figs/figdata/prior\_info.txt}. It differs from the one in the {\tt smooth\_data/Info/} directory in that it has only three columns, though the first columns are identical. You should first copy the files {\tt \$\{MY\_ANALYSIS\}/smooth\_data/Info/prior\_info.txt} and {\tt \$\{MY\_ANALYSIS\}/smooth\_data/Info/observable\_info.txt} to {\tt \$\{MY\_ANALYSIS\}/figs/figdata/}. 
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
..% \textcolor{darkred}{cp $\{MY_ANALYSIS\}/smooth_data/Info/prior_info.txt $\{MY_ANALYSIS\}/figs/figdata/}
..% \textcolor{darkred}{cp $\{MY_ANALYSIS\}/smooth_data/Info/observable_info.txt $\{MY_ANALYSIS\}/figs/figdata/}
\end{Verbatim}
}\vspace*{-8pt}
Then edit the new {\tt prior\_info.txt} file. Keeping only the first two columns, add a third column which provides the \LaTeX-like strings that Matplotlib would use to label the axes. The format for these strings differs from \LaTeX strings in some ways. For example \Verb{\r} must be \Verb{\\r} so as not to conflict with the basic file parsing. The new file can read:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   par0 gaussian ${\textbackslash}theta_0$
   par1 uniform  ${\textbackslash}theta_1$
   par2 gaussian ${\textbackslash}theta_2$
   par3 uniform  ${\textbackslash}theta_3$
   par4 gaussian ${\textbackslash}theta_4$
   par5 uniform  ${\textbackslash}theta_5$
\end{Verbatim}
}\vspace*{-8pt}
Next, edit {\tt \$\{MY\_ANALYSIS\}/figs/figdata/observable\_info.txt}. In this case keep only the first column and list the \LaTeX-like strings into the second column to be used to label axes in the plot. The new file can read:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
obs0  $Y_0$
obs1  $Y_1$
obs2  $Y_2$
obs3  $Y_3$
obs4  $Y_4$
obs5  $Y_5$
obs6  $Y_6$
obs7  $Y_7$
obs8  $Y_8$
obs9  $Y_9$
\end{Verbatim}
}\vspace*{-8pt}
The directory that stores the emulator-vs.-model comparison must be copied next. This directory contains information about the resulting observables for the full model evaluated at 100 randomly chosen points in model-parameter space, along with the emulator predictions. When {\tt fakefullmodel} was run it created data for the full-model calculations and stored them in {\tt smooth\_data/FullModelTestingRuns/}. When {\tt smooth\_testvsfullmodel} it read in the data for those points, then calculated the emulator predictions alongside the true full-model values. This comparison was written to separate files for each observable. These files are in the the directory {\tt smooth\_data/output\_stuff/fullmodel\_testdata/}.To copy the directory to a place where it can be read by the plotting program,
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
..% \textcolor{darkred}{cp -r $\{MY_ANALYSIS\}/smooth_data/output_stuff/fullmodel_testdata $\{MY_ANALYSIS\}/figs/figdata/}
$\end{Verbatim}
}\vspace*{-8pt}
The plotting script is now ready to be executed.
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
..% \textcolor{darkred}{cd $\{MY_ANALYSIS\}/figs/YvsY}
$\{MY_ANALYSIS\}% \textcolor{darkred}{python3 YvsY.py}
--- Observables ---
iY= 0   obs0
iY= 1   obs1
iY= 2   obs2
iY= 3   obs3
iY= 4   obs4
iY= 5   obs5
iY= 6   obs6
iY= 7   obs7
iY= 8   obs8
iY= 9   obs9
Enter iY to designate observable: \textcolor{darkred}{XXX}
XXX of 100  points within 1 sigma
$\end{Verbatim}
}\vspace*{-8pt}
The script prompts you to identify which observable you wish to consider. For the 10 observables, enter the corresponding value of {\tt iY}. The program will tell out of 100 points how many for how many the emulator prediction was within $\pm$ the stated uncertainty of the full-model value. If the uncertainty is accurately stated rougly 68\% of the emulator predictions should fall within this range. A plot, {\tt YvsY.pdf}, is created and presented in Fig. \ref{fig:YvsY_tutorial}
\begin{figure}[hb]
\centerline{\includegraphics[width=\textwidth]{figs/YvsY_tutorial.pdf}}
\caption{\label{fig:YvsY_tutorial}
Comparison of full-model values (black squares) to emulator values (red circles) for 100 points in model-parameter space. The uncertainties are solely those associated with the emulation. If the uncertainties were accurately expressed, 68\% of the points would lie within the uncertainty intervals, and in this case 65 emulator predictions were within the emulator's stated uncertainty. It is not unusual for the estimated uncertainty to be somewhat higher or lower what the User would find, even if the User were to evaluate a very large number of points.}
\end{figure}

The last two programs, {\tt smoothy\_testattrainingpts} and {\tt smoothy\_testvsfullmodel} both built and trained the emulator. If the emulator has already been built and trained from a previous run, one can save computational cost by using the hyper-parameters stored from a previous training. These are in {\tt smooth\_data/output\_stuff/sigmalambda.txt}. They can be read from the main programs by using one of the {\tt ReadSigmaLambda()} methods. One cana then tune by using the {\tt TuneAllYFixedLambda()} method.  Unless the model-parameter space is a high dimension, this is rarely worth the effort because tuning might take only a second or two. More detailed explanations can be found in Sec. \ref{sec:emulator}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Exploring and Analyzing the Posterior via MCMC}

Given the experimental information, which is stored in {\tt smooth\_data/Info/experimental\_info.txt}, one can then use the tuned emulator to explore the posterior likelihood through MCMC, which works via a Metropolis algorithm. The file {\tt smooth\_data/Info/experimental\_info.txt} provided in the template is:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
obs0  57.840878  10.0 0.0
obs1  -85.613188  10.0 0.0
obs2  43.335184  10.0 0.0
obs3  40.159450  10.0 0.0
obs4  38.013337  10.0 0.0
obs5  64.492673  10.0 0.0
obs6  -195.300157  10.0 0.0
obs7  99.587427  10.0 0.0
obs8  7.963056  10.0 0.0
obs9  68.844147  10.0 0.0
\end{Verbatim}
}\vspace*{-8pt}
The first column is the list of observable names, which should be identical to those listed in {\tt smooth\_data/Info/observable\_info.txt}. The second and third columns lists the experimental measurement, $Y_a$, and the experimental uncertainty, $\sigma_{a}^{\rm exp}$. The last column lists the additional uncertainty due to shortcomings of the model, $\sigma_a^{\rm theory}$, i.e. missing or not exactly represented physics. For the purposes of comparing theory to data, only the combination $(\sigma_a^{\rm exp})^2+(\sigma_a^{\rm theory})^2+(\sigma_a^{\rm emu})^2$ comes into play, because this combination appears in the likelihood for the posterior,
\begin{align*}\eqnumber
\mathcal{L}(\vec{\theta})&=\prod_{a}\frac{1}{\sqrt{2\pi(\sigma_a^{\rm tot})^2}}
\exp\left\{-\frac{(Y_a(\vec\theta)-Y_{a}^{\rm exp})^{2}}{2(\sigma_a^{\rm tot})^2}\right\}\\
(\sigma_a^{\rm tot})^2&=(\sigma_a^{\rm exp})^2+(\sigma_a^{\rm theory})^2+(\sigma_a^{\rm emu})^2.
\end{align*}
Whereas the emulator uncertainty, $\sigma_a^{\rm emu}$, depends on the location in parameter space, $\vec{\theta}$, the other two contributions are assumed to be independent of $\vec{\theta}$.

There are options for the MCMC, which are stored in {\tt smooth\_data/Options/mcmc\_options.txt}. For the tutorial template, that file is
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 # This is for the MCMC search of parameter space
 # (not for the emulator tuning)
 #LogFileName smoothlog.txt # comment out for interactive running
 MCMC_METROPOLIS_STEPSIZE 0.06
 MCMC_IGNORE_EMULATOR_ERROR false
 MCMC_NBURN  10000
 MCMC_NTRACE 100000
 MCMC_NSKIP  5
 MCMC_IGNORE_EMULATOR_ERROR false
 RANDY_SEED  12345
\end{Verbatim}
}\vspace*{-8pt}
The Metropolis step size should be adjusted so that the Metropolis success rate is approximately one half. The success rate prints out when the {\tt mcmc} code runs. If the success rate is anywhere between 20 and 80\%, this should be fine. But, if the rate is close to zero or close to 100\%, the efficiency of the procedure suffers. It is recommended to run the MCMC code with a modest number of steps, then adjust the step size accordingly. The parameter {\tt MCMC\_NBURN} sets the number of Metropolis steps to be used in the ``burn-in'' stage, i.e. before one begins to store the trace. The number of elements to store in the trace in {\tt MCMC\_NTRACE}, and {\tt MCMC\_NSKIP} sets the number of steps to skip before storing a new point in the trace. Thus, if {\tt MCMC\_NTRACE} is one million and if {\tt MCMC\_NSKIP}=5, then the procedure will perform 5 million steps, and store every fifth one, leading to one million stored points in the trace. Finally, {\tt RANDY\_SEED} sets the random number seed. Options are explained in greater detail in Sec. \ref{sec:mcmc}.

The source code, {\tt \{MY\_LOCAL\}/bin/smoothy\_mcmc\_main.cc}, is rather simple.
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   //Next two lines can take replace of TuneAllY() if you have previously tuned and wish to speed calculations
   //master.ReadSigmaLambda(); //Next two lines can take place of TuneAllY() if you have previously tuned and wish to speed calculations
   //master.TuneAllYFixedLambda();
   NBandSmooth::CMCMC mcmc(&master);
        
   unsigned int Nburn=master.parmap->getI("MCMC_NBURN",1000);  // Steps for burn in
   unsigned int Ntrace=master.parmap->getI("MCMC_NTRACE",1000); // Record this many points
   unsigned int Nskip=master.parmap->getI("MCMC_NSKIP",5); // Only record every Nskip^th point
                
   mcmc.PerformTrace(1,Nburn);     
   CLog::Info("finished burn in{\textbackslash}n");
        
   mcmc.PruneTrace(); // Throws away all but last point
   mcmc.PerformTrace(Ntrace,Nskip);
   mcmc.WriteTrace(); // Writes trace
   mcmc.EvaluateTrace();

return 0;
\}
\end{Verbatim}
}\vspace*{-8pt}
After tuning the emulator one creates an {\tt CMCMC} object. One then runs a trace for {\tt Nburn} steps. During the burn-in stage none of the points are stored. The trace is then pruned, keeping only the last point. Starting a new trace every {\tt Nskip}$^{\rm th}$ point is recorded, until the list of newly recorded points is {\tt Ntrace} long. The trace is then written to file. Finally, the method {\tt EvaluateTrace()} analyzes the trace and calculates several averages and covariances, which are then stored in the {\tt smooth\_data/MCMC/} directory in several files.

Running the MCMC program gives the following output:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}] 
$\{MY_ANALYSIS\}/rhic% \textcolor{darkred}{\$\{MY_LOCAL\}/bin/smoothy_mcmc}
At beginning of Trace, LL=-36.833553
At end of trace, best LL=-23.300576
Best Theta=
0.179984  0.170064  0.240206  0.203989  0.176251  0.220042  
Metropolis success percentage=48.760000
finished burn in
At beginning of Trace, LL=-26.770854
finished 10%
finished 20%
finished 30%
finished 40%
finished 50%
finished 60%
finished 70%
finished 80%
finished 90%
finished 100%
At end of trace, best LL=-23.278385
Best Theta=
0.220576  0.180758  0.204556  0.182533  0.183560  0.183437  
Metropolis success percentage=48.341200
writing trace, ntrace = 100001
\end{Verbatim}
}\vspace*{-8pt}
Here {\tt best LL} refers to the log-likelihood and {\tt Best Theta} refers to the value of $\vec{\theta}$ that gave the maximum log-likelihood. Values of {\tt Best Theta} and {\tt best LL} are given after the burn-in and after the trace. The ``experimental'' values were generated by running the full model with all 6 values, $\theta_i$, set to 0.2, so the fact that the best value of $\vec{\theta}$ found was close to that point is a validation of the method.

The trace is written to {\tt smooth\_data/MCMC\_trace/trace\_theta.txt}. It lists the scaled model parameters,
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
theta_1 theta_2 theta_3 theta_4 ...
theta_1 theta_2 theta_3 theta_4 ...
theta_1 theta_2 theta_3 theta_4 ...
\end{Verbatim}
}\vspace*{-8pt}
A similar file, {\tt smooth\_data/MCMC\_trace/trace\_X.txt}, shows the trace in terms of the unscaled model parameters. If {\tt MCMC\_NTRACE} is set to a million, there would be a million lines in each file.

To view the posterior likelihood, first move the trace information to a location where it can be read by the plotting program.
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}] 
$\{MY_ANALYSIS\}/rhic% \textcolor{darkred}{cp $\{MY_ANALYSIS\}/smooth_data/MCMC/trace_theta.txt $\{MY_ANALYSIS\}/figs/figdata/}
\end{Verbatim}
}\vspace*{-8pt}
Next, move into the {\tt figs/posterior/} directory and run the Python script:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
..% \textcolor{darkred}{cd $\{MY_ANALYSIS\}/figs/posterior}
${MY_ANALYSIS}/figs/posterior% \textcolor{darkred}{python3 posterior.py}
${MY_ANALYSIS}/figs/posterior% Number of points in trace = 100001
\end{Verbatim}
}\vspace*{-8pt}
The script should create a figure, {\tt posterior.pdf}, shown in Fig. \ref{fig:posterior_tutorial}
\begin{figure}
\centerline{\includegraphics[width=4.5in]{figs/posterior_tutorial.pdf}}
\caption{\label{fig:posterior_tutorial}
Projections for the posterior likelihood from the MCMC trace. The contour lines represent $1-\sigma$, $2-\sigma$ and $3-\sigma$ likelihoods.}
\end{figure}
The likelihood is projected for individual model parameters (along the diagonal), or for pairs (off-diagonal). The plot is in terms of the scaled variables, $\theta_i$. To translate to the true model-parameter ranges, one can look at the {\tt smooth\_data/Info/modelpars\_info.txt} file, which gives the prior ranges of the model parameters before they are scaled to the -1 to 1 range. The file {\tt figs/directions.pdf} shows how the User can alter the plot. For example there is a line in the python script, {\tt ParsToPlot=[1,2,3,4,5,0]}, which you can edit to change the ordering of the model-parameters, and to choose which model parameters are considered.

\subsubsection{Viewing the Resolving Power}

The program also calculates various covariances:
$\langle\langle\delta\theta_i\delta\theta_j\rangle\rangle$,  $\langle\langle\delta\theta_i\delta Y_a\rangle\rangle$, and $\langle\langle\delta Y_a\delta Y_b\rangle\rangle$. The quantities $\langle\langle....\rangle\rangle$ refer to averages over the  posterior, i.e. averages over the trace. The eigenvalues and eigenvectors of $\langle\langle\delta\theta_i\delta\theta_j\rangle\rangle$ are also recorded. Hopefully, the User will find the file names in {\tt smooth\_data/MCMC/} to be self-explanatory. The files describing the posterior-weighted average, $\langle\langle \vec{\theta}\rangle\rangle$, and the posterior covariances, $\langle\langle\delta\theta_i\delta\theta_j\rangle\rangle$, are also in the directory. Other file lists the eigenvectors and eigenvalues of the covariance matrix. 

One measure of the resolving power is:
\begin{align*}\eqnumber
\mathcal{R}_{ia}&\equiv\frac{d\langle\langle\theta_i\rangle\rangle}{dY_a^{\rm exp}}\langle \delta Y_a^2\rangle^{1/2}.
\end{align*}
This quantifies how the posterior value of $\theta_i$ changes as the experimental value changes if the experimental value, $Y_a^{\rm exp}$, changes an amount characteristic of the variance of $Y_a$ across the prior. Higher values of $\mathcal{R}_{ia}$ for different $a$ demonstrate the relative contributions of different observables $a$ to constrain a model parameter $i$. The resolving power matrix is written to {\tt MCMC\_trace/ResolvingPower.txt}. The resolving power is a function of the covariances listed above (see \href{preprint.pdf}{\tt preprint.pdf}). The data for the resolving power was also created by running {\tt smoothy\_mcmc}. To plot the resolving power move the data file {\tt smooth\_data/MCMC/ResolvingPower.txt} to {\tt figs/figdata/}. You can then run the PYTHON script:
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
..% \textcolor{darkred}{cp $\{MY_ANALYSIS\}/smooth\_data/MCMC/ResolvingPower.txt $\{MY_ANALYSIS\}/figs/figdata/}
..% \textcolor{darkred}{cd $\{MY_ANALYSIS\}/figs/resolvingpower}
$\{MY_ANALYSIS\}/figs/resolvingpower% \textcolor{darkred}{python3 RP.py}
NPars= 6  NObs= 10
\end{Verbatim}
}\vspace*{-8pt}
The resulting figure, {\tt RP.pdf}, is shown if Fig. \ref{fig:RP_tutorial}
\begin{figure}[hb]
\begin{minipage}{0.4\textwidth}
\includegraphics[width=0.9\textwidth]{figs/RP_tutorial.pdf}
\end{minipage}
\begin{minipage}{0.6\textwidth}
\caption{%\label{fig:RP_tutorial}
Resolving Power. Red bars represent positive correlations with $Y^{\rm exp}_a$ and $\theta_i$. Larger bars suggest that the particular observable contributes more to the constraint of the particular model parameter.}
\end{minipage}
\end{figure}

If the User has an Apple computer, or is running Linux with the PDF viewer, {\tt okular}, the User can edit the python scripts mentioned above and uncomment the approriate line shown in green and comment out the {\tt plt.show()} and {\tt plt.close()} lines. The lines at the end of {\tt RP.py} are
\vspace*{-8pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 .
plt.show()
plt.close()
# if you have Mac OS and want to see pdf file, comment out previous two lines and uncomment line below
\textcolor{darkgreen}{#os.system("open -a Preview "+outputfilename);}
# if you have Linux and want to see pdf file, comment out previous two lines and uncomment line below
\textcolor{darkgreen}{#os.system("okular "+outputfilename+"&");}
 .
\end{Verbatim}
}\vspace*{-8pt}
The User can then see the actual PDF file while the script is running. Similar changes can be made to all three PYTHON plotting scripts mentioned here.

\end{document}
