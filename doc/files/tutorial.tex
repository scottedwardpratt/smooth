\documentclass[UserManual.tex]{subfiles}
\begin{document}
\setcounter{section}{7}
\section{Tutorial}\label{sec:tutorial}

\subsection{Overview}

Working through the steps in this section constitutes a tutorial, consisting of the following steps.
\begin{enumerate}\itemsep=0pt
\item Copy the required files from the template directory to the User's space, and compile the main programs.
\item Set up the information files describing the priors and observable names.
\item Run {\it Simplex Sampler} to generate the model-parameter values at which the full model will be trained.
\item Run a full model to generate the observables for each of the full-model runs.
\item Tune {\it Smooth Emulator} and write the coefficients to file.
\item Run a program that prompts the User for the coordinates of a point in parameter space, then returns the emulator prediction with its uncertainty.
\end{enumerate}



\subsubsection{Setting up the Directory and Compiling the Main Programs}
The source code for the main programs
A analysis directory template is provided with the intention that the User will copy the directory to their own space, then use this as a foundation from which to embark on their own analysis. This template also provides the files for a tutorial. To copy the templates,
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 % \textcolor{darkred}{cp -r ${SMOOTH_HOME}/AnalysisTemplate /Users/CarlosSmith/MyAnalysis}
\end{Verbatim}
}\vspace*{-12pt}
Here, {\tt ../MyAnalysis} can be replaced by any directory name the User chooses.

Installation and compilation is described in Sec. \ref{sec:installation}. As was defined in that section, the tutorial will refer to three locations with the short hand:

\vspace*{0.05in}

\begin{tabular}{rl}\hline
{\tt \$\{SMOOTH\_HOME\}} & \parbox{5in}{~\\Location of Git Repository, e.g. \sloppypar{\tt /Users/CarlosSmith/bandframework/software/SmoothEmulator}\\}\\
{\tt \$\{MY\_LOCAL\}} & \parbox{5in}{Can be placed anywhere. Executables are store in \sloppypar{\tt \$\{MY\_LOCAL\}/bin} and main programs, and source codes for main\\ programs are found within {\tt \$\{MY\_LOCAL\}/software/main\_programs}\\}\\
{\tt \$\{MY\_ANALYSIS\}} & \parbox{5in}{Can be placed anywhere. Work spaces where parameter files, data, results and figures are created and stored. User may have several different such directories\\}\\
 \hline
\end{tabular}

The User should have also compile the main libraries, if not done already,

\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   $\{SMOOTH_HOME\}/software% \textcolor{darkred}{cmake .}
   $\{SMOOTH_HOME\}/software% \textcolor{darkred}{make}
\end{Verbatim}
}\vspace*{-12pt}

and the main programs,
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   $\{MY_LOCAL\}/software% \textcolor{darkred}{cmake .}
   $\{MY_LOCAL\}/software% \textcolor{darkred}{make}
\end{Verbatim}
}\vspace*{-12pt}

This will compile all the main source programs in {\tt \$\{MY\_LOCAL\}/software/MainPrograms/} and two programs used to generate files for the tutorial in {\tt \$\{MY\_LOCAL\}/software/TutorialPrograms/}. The repository was organized to encourage Users to edit any files in {\tt \$\{MY\_LOCAL\}/}. If the User wishes to restore any original files, a copy can be found at {\tt \$\{SMOOTH\_HOME\}/}.

Several executables should now appear in \sloppypar{\tt \$\{MY\_LOCAL\}/bin/}: \sloppypar{\tt trainingpoint\_optimizer, smoothy\_testattrainingpts, smoothy\_testvsfullmodel, smoothy\_calcobs, smoothy\_mcm}, which all involve the emulator. Tow other executables, {\tt fakefullmodel} and {\tt fakeinfo} are only used for the tutorial. The User might find it convenient to add \sloppypar{\tt \$\{MY\_LOCAL\}/bin} to their path. The reason these are compiled in the User's space, separate from the main libraries, is that the User may well wish to create their own main programs, and this arrangement allows the User to compile their own versions, while leaving the bulk of the source code unchanged. 

\subsection{Creating the Necessary Info Files}
The User will run the software from the {\tt \$\{MY\_ANALYSIS\}/} directory. Before a User can run the {\it Smooth Emulator} executables they must create text files that describe the model-parameter priors and list the observable names. These three files need to be in the {\tt \$\{MY\_ANALYSIS\}/smooth\_data/Info/} directory. The first file, {\tt smooth\_data/Info/prior\_info.txt}, describes the model parameters and their priors. This file is For the purposes of this tutorial, we consider a model with six model parameters:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
# par_name dist_type  xmin/centroid xmax/width  SensitivityScale
   par0 gaussian 0 100    1.00000
   par1 uniform -100 100  1.00000
   par2 gaussian 0 100    1.00000
   par3 uniform -100 100  1.00000
   par4 gaussian 0 100    1.00000
   par5 uniform -100 100  1.00000
\end{Verbatim}
}\vspace*{-12pt}
Thus, the model has six parameters. The second entry in each line is either {\tt uniform} or {\tt gaussian}. If the entry is {\tt uniform}, the last two numbers represent the range of the uniform prior, $x_{\rm min}$ and $x_{\rm max}$. If the second entry is {\tt gaussian} the third entry represents the center of the Gaussian distribution and the fourth represents the width. The final column represents the sensitivity scale, which must be between zero and 1.0. For the most impactful parameters, this should be set to 1.0. If a parameter is expected to provide little variance compared to the most impactful parameters, this should be set to some fraction. Roughly, if a parameter is expected to provide half as much variance as the most important parameters, it should be set to 0.5. For a full model, the User would replace this file with one appropriate for their own model. This file is required for training-point optimization, for tuning, and for the MCMC programs.  

The second file is {\tt smooth\_data/Info/observable\_info.txt}. This describes output values from the model. In the template, the file describes, in this case, ten observables:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
# ObservableName   ALPHA
   obs0 0
   obs1 0
   obs2 0
   obs3 0
   obs4 0
   obs5 0
   obs6 0
   obs7 0
   obs8 0
   obs9 0
\end{Verbatim}
}\vspace*{-12pt}
The first entry in each line simply provides the names of the observable which will be processed in the Bayesian analysis.  The second entry describes the point-to-point noise is used by both the training-point optimizing programs and by the emulator tuning programs. Here, {\tt ALPHA} is the noise as a fraction of the characteristic variation of the observable, $\sigma_Y$. Noise refers to variations of the model that would occur if the model were rerun with the same model parameters, which is typically due to some finite sampling inherent to the model, e.g. if the particle is calculating the average energy of particles using a simulation, and if a finite number of simulations and particles are sampled, the observable might vary from run to another. If one expects that random uncertainty to be 5\% of the variation of the observable throughout the model parameter space, then {\tt ALPHA} would be 0.05. {\it Smooth Emulator} software assumes that this noise is the same for all the full calculations of the same observable. I.e., if 20 training runs were performed at different points in model-parameter space, the software assumes that the {\tt ALPHA} was not much different at one training point than at another. If {\tt ALPHA} is set to zero, the emulator will exactly reproduce the observables from the full model when evaluated at the training points. If one performed training runs with simulations using grossly different numbers of events at one training point vs another, then this shortcoming could potentially be an issue. This file is required by both the tuning and MCMC programs.

The third, and final file, {\tt smooth\_data/Info/experimental\_info.txt}, describes the actual measurements and only comes into play at the time the MCMC is being performed. The file in the tutorial might look like this:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
obs0  57.840878  10.0 0.0
obs1  -85.613188  10.0 0.0
obs2  43.335184  10.0 0.0
obs3  40.159450  10.0 0.0
obs4  38.013337  10.0 0.0
obs5  64.492673  10.0 0.0
obs6  -195.300157  10.0 0.0
obs7  99.587427  10.0 0.0
obs8  7.963056  10.0 0.0
obs9  68.844147  10.0 0.0 
\end{Verbatim}
}\vspace*{-12pt}
The names of the observables must match those listed in the {\tt observable\_info.txt} file. The second column is the value reported by the experiment and the third column is the reported uncertainty. The uncertainty cannot be set to zero. The last column represents the model's uncertainty due to missing physics, i.e. not the uncertainty due to noise in the calculation. The contribution from random noise is incorporated into the emulator uncertainty. The uncertainty due to missing physics can be thought of as the error, or deviation from a perfect measurement, one might expect if one used the precisely correct parameters. One can think of this as the systematic error of the theory on which the model is built. For the purpose of the MCMC, the three uncertainties, that of the emulator, that from the experiment, and the model's systematic theoretical error, are all added in quadrature to provide the uncertainty relevant for calculating the log-likelihood in the MCMC.

The User needs to edit the three files above according to their project. For the purpose of this tutorial, the user should run the program {\tt fakeinfo}, which prompts the User for the number of model parameters and observables. 
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   $\{MY_ANALYSIS\}/software% \textcolor{darkred}{$\{MY_LOCAL\}/bin/fakeinfo}
\end{Verbatim}
}\vspace*{-12pt}
This program creates the {\tt Info} files for a model with 6 model parameters and 10 observables. The three info files should appear like those shown above.

\subsection{Running {\tt trainingpoint\_optimizer}}

Before running {\tt trainingpoint\_optimizer} the User should inspect or edit the options file, {\tt smooth\_data/Options/tpo\_options.txt}. A template for this file is provided:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
TPO_Method  MCQuadratic  # can be "MC", "MCSphere", "MCSimplex", "MCSimplexPlus1", "MCQuadratic", "MCSphereQuadratic"
TPO_NTrainingPts    0   # only relevant for OptimizeMethod="MCSphere" or "MC"
TPO_NMC  10000
TPO_ALPHA 0.01 # does not have to be the same value used to train emulator
TPO_Include_LAMBDA_Uncertainty true # dangerous to set this to false
TPO_FullModelRunsDirName  smooth_data/FullModelRuns
#TPO_ReadPoints 0,1,4-7,10,11-13,21
#TPO_FreezePoints 0,1,4-7,10,11-13,21
\end{Verbatim}
}\vspace*{-12pt}
Options are described in detail in Sec. \ref{sec:tpo}.

Now the user can run {\tt trainingpoint\_optimizer}, which is meant to be run interactively. This will generate a list of coordinates in model-parameter space for each of $N_{\rm train}$ training points. Simply run the program by calling the command. The output to the screen is:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
${MY_ANALYSIS}% \textcolor{darkred}{${MY_LOCAL}/bin/trainingpoint_optimizer}
NTrainingpts=28, NMC=10000, LAMBDA=3.00, ALPHA=0.010
Optimize_MC: at beginning: bestSigma2=0.014520
+++ finished 1%, expected accuracy=0.01331, success %=39, step size=0.0094491
+++ finished 2%, expected accuracy=0.011875, success %=33, step size=0.015213
+++ finished 3%, expected accuracy=0.01119, success %=20, step size=0.020842
 .
+++ finished 99%, expected accuracy=0.0072313, success %=14, step size=0.00043523
+++ finished 100%, expected accuracy=0.0072312, success %=26, step size=0.00026549
\end{Verbatim}
}\vspace*{-12pt}
?????? The output ----------------------

The program writes information about the training points in the {\tt smooth\_data/FullModelRuns/} directory. Changing into that directory, there should now be 28 sub-directories, corresponding to the 28 training points: {\tt FullModelRuns/run0}, {\tt FullModelRuns/run1}, {\tt FullModelRuns/run2} $\cdots$. Each directory has one text file describing the training points. For example, the {\tt modelruns/run21/model\_parameters.txt} file might be 
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 par0 -145.307
 par1 -6.8244
 par2 -67.4252
 par3 62.3719
 par4 -85.451
 par5 -29.6548
\end{Verbatim}
}\vspace*{-12pt}
This describes the six model parameters, which will serve as the input for that model run.  The next step will be to run the full model for the parameters in each directory.

In this example, {\tt trainingpoint\_optimizer} was run with {\tt TPO\_Method} set to {\tt MCQuadratic}. This choice automatically set the number of training points to 28 given that there were six model parameters and 28 points are required to fully constrain a quadratic fit. If the option had been set to {\tt MCSimplex}, 7 points would have been chosen, the minimum number to constrain a linear fit (If all the priors were Gaussian, this would result in a simplex arrangement). If {\tt TPO\_Method} had been set to {\tt MC}, {\tt trainingpoint\_optimizer} would have used the option {\tt TPO\_NTrainingPts} to set the number of training points. The full range of options is described in Sec. \ref{sec:tpo}.

\subsection{Running the Full Model}
Once the training points have been generated, the User will run the full model at each training point. For the tutorial, a fake full model is provided. It reads the model-parameter values in each {\tt smooth\_data/modelruns/runI/model\_parameters.txt} file and writes the corresponding observables for each point in model-parameter space, {\tt I}, in the file {\tt smooth\_data/modelruns/runI/obs.txt}.

The User needs to run the program {\tt fakefullmodel}, which is interactive. Running the model, the User should see something like:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   $\{MY_ANALYSIS\}% \textcolor{darkred}{$\{MY_LOCAL\}/bin/fakefullmodel}
   NPars=6, NObs=10
   Creating Fake Model Data for 28 Training Pts
\end{Verbatim}
}\vspace*{-12pt}
The output simply shows the number of model parameters, observables, and training points. The number of model parameters was found by reading {\tt smooth\_data/Info/prior\_info.tt} and the number of training points was determined by counting the number of files in {\tt smooth\_data/FullModelRuns}. The fake model is built on a Taylor expansion with random coefficients, chosen to be consistent with the form assumed by the emulator. This form is built on the choices of $\Lambda=3.0$ and $\Sigma_A=100$. 

Inspecting one of the output files, {\tt smooth\_data/FullMode/run0/obs.txt},
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 obs0 77.444888
 obs1 -78.684124
 obs2 62.298517
 obs3 109.230134
 obs4 70.629874
 obs5 106.994538
 obs6 -196.814283
 obs7 9.158107
 obs8 -29.184781
 obs9 41.295872
\end{Verbatim}
}\vspace*{-12pt}
The second column provides the value of the specified observable for the full model at that specific training point. Additionally, {\tt fakefullmodel} created a directory {\tt smooth\_data/FullModelTestingRuns/} which stores information about full-model runs at randomly chosen points in the model-parameter space. These points and their corresponding data are not used for tuning. This data can be used later to test the emulator. The User need not create such files for their project, unless they wish to have some separate runs just for testing. 

\subsection{Running the Emulator}
Before building and tuning the emulator, the User needs to edit one additional file, the parameter file that sets numerous options for {\it Smooth Emulator}. This file is {\tt smooth\_data/Options/emulator\_options.txt}. For the template used in this tutorial, the contents of that file appear as
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
  # Location of output, comment out for interactive running
  # LogFileName smoothlog.txt
  SmoothEmulator_FixLambda false // If false will adjust optimize LAMBDA (false is default)
  # Smoothness parameter to start maximizing procedure
  SmoothEmulator_LAMBDA 3.0    # If SmoothEmulator_FixLambda is true, this fixes LAMBDA
                               #otherwise this is just a starting point for optimization search
  #
  # Choose read/write format for training data (SMOOTH or SURMISE), default is SMOOTH
  # If format is SMOOTH
  SmoothEmulator_TrainingFormat SMOOTH
  #SmoothEmulator_TrainingFormat SURMISE
  # Location of training data (if SMOOTH FORMAT) default is smooth_data/FullModelRuns
  SmoothEmulator_FullModelRunsDirName smooth_data/FullModelRuns
  # Location of training data (if SURMISE FORMAT) default is SurmiseTrainingPoints.txt
  #SmoothEmulator_SurmiseTrainingPointsFilename SurmiseTrainingPoints.txt
  # Location of Observables (if SURMISE FORMAT)
  #SmoothEmulator_SurmiseTrainingObsFilename SurmiseTrainingObs.txt
  #
  # Choose which runs to use for training. Can be set to "all" or as list, e.g. 1-5,8-12,15,18
  SmoothEmulator_TrainingPts all
  #
  # Below only used for testing agains full model runs not used for training.
  # Choose read/write format for testing data (SMOOTH or SURMISE), default is SMOOTH
  SmoothEmulator_TestingFormat SMOOTH
  #SmoothEmulator_TestingFormat SURMISE # Note this is not tested
  # For Smooth format default location of testing data is smooth_data/FullModelTestingRuns/
  SmoothEmulator_FullModelTestingRunsDirName smooth_data/FullModelTestingRuns
  #
  # List of points to be used for testing, all is default, can list, e.g. 1-5,8-12,15,18
  SmoothEmulator_TestingPts all
  #
  # When calculating uncertainty, include(or not) the contribution from Lambda varying
  SmoothEmulator_INCLUDE_LAMBDA_UNCERTAINTY true
\end{Verbatim}
}\vspace*{-12pt}
More options are described in detail in Sec. \ref{sec:emulator}. The tutorial will use the default format (not that of the SURMISE format) because the tutorial recorded the training-point information in the {\it Smooth Emulator} format.

There are two pre-constructed main programs to demonstrate the tutorial: {\tt \$\{MY\_LOCAL\}/bin/smoothy\_testattrainingpts} and {\tt \$\{MY\_LOCAL\}/bin/smoothy\_testvsfullmodel}. The corresponding source code for the first is {\tt \$\{MY\_LOCAL\}/software/MainPrograms/smoothy\_testattrainingpts\_main.cc},
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
#include "msu_smoothutils/parametermap.h"
#include "msu_smooth/master.h"
#include "msu_smoothutils/log.h"

using namespace std;
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   master.TestAtTrainingPts();
   return 0;
\}
\end{Verbatim}
}\vspace*{-12pt}
and the source code for the second is similarly simple,
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
#include "msu_smoothutils/parametermap.h"
#include "msu_smooth/master.h"
#include "msu_smoothutils/log.h"

using namespace std;
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   master.TestVsFullModel();
   return 0;
\}
\end{Verbatim}
}\vspace*{-12pt}
As one would guess from the source code, the first program builds and tunes the emulator for all the observables through the call {\tt master.TuneAllY()}. The second line, {\tt master.TestAtTrainingPts()}, runs the emulator at each of the training points and compares to the training values. These are interactive programs and running {\tt smoothy\_testattrainingpts} should give an output like:
vIn the tuning of the emulator, the hyper-parameters $\Lambda$ and $\Sigma_A$ are chosen. The program {\tt fakefullmodel} was built based on a randomized Taylor expansion consistent with $\Lambda=3.0$ and $\Sigma_A=100$. Due to the finite number of training points (in this case 28) the emulator's value differs from these values. The output would continue to compare the emulator to the training points at each point, and for each of the 10 observables. The last column of the output is the emulator's uncertainty. 

The second program, {\tt smoothy\_testvsfullmodel} also constructs and tunes the emulator. But in this case, the program compares the full model to the emulated values away from the training points. The data for the full model was created by the {\tt fakefullmodel} program, and is found in {smooth\_data/FullModelTestingRuns}. Testing data was created for 50 random points in model-parameter space. Again, the source code is rather simple.
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
#include "msu_smoothutils/parametermap.h"
#include "msu_smooth/master.h"
#include "msu_smoothutils/log.h"

using namespace std;
int main()\{
   NBandSmooth::CSmoothMaster master;
   master.TuneAllY();
   master.TestVsFullModel();
   return 0;
\}
\end{Verbatim}
}\vspace*{-12pt}
To run the program,
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
$\{MY_ANALYSIS\}% \textcolor{darkred}{smoothy_testvsfullmodel}
iY=0: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.857423
percent < 1 sigma = 44.000000
iY=1: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=0.965030
percent < 1 sigma = 72.000000
iY=2: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.138670
percent < 1 sigma = 65.000000
iY=3: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=3.380905
percent < 1 sigma = 65.000000
iY=4: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.080057
percent < 1 sigma = 58.000000
iY=5: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=0.833119
percent < 1 sigma = 77.000000
iY=6: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.698096
percent < 1 sigma = 54.000000
iY=7: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.739706
percent < 1 sigma = 46.000000
iY=8: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=1.089194
percent < 1 sigma = 63.000000
iY=9: (<(Y-Yreal)^2>/SigmaY^2_emulator)^1/2=0.874994
percent < 1 sigma = 80.000000
\end{Verbatim}
}\vspace*{-12pt}



One can now peruse the files in {\tt smooth\_data/output\_stuff/fullmodel\_testdata/} and see the comparison of the 50 emulator values to the values calculated by {\tt fakefullmodel}. 



Given that the tuning is very fast, there is little need to write the coefficients as any subsequent use of the emulators can simply repeat the tuning, rather than reading in the coefficients. However, for large numbers of training points and model parameters, it might make sense to used stored values of the emulator's hyper-parameters to avoid recalculating them. Those parameters are stored in {\tt smooth\_data/output\_stuff/sigmalambda.txt}.

Hopefully, the User will find the source codes used in this tutorial to be fairly self-explanatory. Nonetheless, detailed explanations can be found in Sec. \ref{sec:emulator}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Exploring the Posterior via Markov-Chain Monte-Carlo}

Given the experimental information, which is stored in analysis directory in {\tt smooth\_data/Info/experimental\_info.txt}, one can then use the tuned emulator to explore the posterior likelihood through MCMC, which works via a Metropolis algorithm. The file {\tt smooth\_data/Info/experimental\_info.txt} provided in the template is:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
obs0  57.840878  10.0 0.0
obs1  -85.613188  10.0 0.0
obs2  43.335184  10.0 0.0
obs3  40.159450  10.0 0.0
obs4  38.013337  10.0 0.0
obs5  64.492673  10.0 0.0
obs6  -195.300157  10.0 0.0
obs7  99.587427  10.0 0.0
obs8  7.963056  10.0 0.0
obs9  68.844147  10.0 0.0
\end{Verbatim}
}\vspace*{-12pt}
The first column is the list of observable names, which should be identical to those listed in {\tt smooth\_data/Info/observable\_info.txt}. The second and third columns lists the experimental measurement, $Y_a$, and the experimental uncertainty, $\sigma_{a}^{\rm exp}$. The last column lists the additional uncertainty due to shortcomings of the model, $\sigma_a^{\rm theory}$, i.e. missing or not exactly represented physics. For the purposes of comparing theory to data, only the combination $(\sigma_a^{\rm exp})^2+(\sigma_a^{\rm theory})^2+(\sigma_a^{\rm emu})^2$ comes into play, because this combination appears in the likelihood for the posterior,
\begin{align*}\eqnumber
\mathcal{L}(\vec{\theta})&=\prod_{a}\frac{1}{\sqrt{2\pi(\sigma_a^{\rm tot})^2}}
\exp\left\{-\frac{(Y_a(\vec\theta)-Y_{a}^{\rm exp})^{2}}{2(\sigma_a^{\rm tot})^2}\right\}\\
(\sigma_a^{\rm tot})^2&=(\sigma_a^{\rm exp})^2+(\sigma_a^{\rm theory})^2+(\sigma_a^{\rm emu})^2.
\end{align*}
Whereas the emulator uncertainty, $\sigma_a^{\rm emu}$, depends on the location in parameter space, $\vec{\theta}$, the other two contributions are assumed to be independent of $\vec{\theta}$.

There are options for the MCMC, which are stored in {\tt smooth\_data/Options/mcmc\_options.txt}. For the tutorial template, that file is
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 # This is for the MCMC search of parameter space
 # (not for the emulator tuning)
 #LogFileName smoothlog.txt # comment out for interactive running
 MCMC_LANGEVIN false
 MCMC_METROPOLIS_STEPSIZE 0.01
 MCMC_LANGEVIN_STEPSIZE 0.5
 MCMC_IGNORE_EMULATOR_ERROR false
 MCMC_NBURN  5000
 MCMC_NTRACE 50000
 MCMC_NSKIP  5
 MCMC_IGNORE_EMULATOR_ERROR false
 RANDY_SEED  12345
\end{Verbatim}
}\vspace*{-12pt}
The first parameter, {\tt MCMC\_LANGEVIN} should be set to {\tt false}, as the Langevin MCMC (as opposed to the Metropolis version) is under development (also it might not be finished because it does not seem to significantly improve performance). The Metropolis step size should be adjusted so that the Metropolis success rate is approximately one half. The success rate prints out when the {\tt mcmc} code runs. If the success rate is anywhere between 20 and 80\%, this should be fine. But, if the rate is close to zero or close to 100\%, the efficiency of the procedure suffers. It is recommended to run the MCMC code with a modest number of steps, then adjust the step size accordingly. 

The parameter {\tt MCMC\_NBURN} sets the number of Metropolis steps to be used in the ``burn-in'' stage, i.e. before one begins to store the trace. The number of elements to store in the trace in {\tt MCMC\_NTRACE}, and {\tt MCMC\_NSKIP} sets the number of steps to skip before storing a new point in the trace. Thus, if {\tt MCMC\_NTRACE} is one million and if {\tt MCMC\_NSKIP}=5, then the procedure will perform 5 million steps, and store every fifth one, leading to one million stored points in the trace. Finally, {\tt RANDY\_SEED} sets the random number seed. Options are explained in greater detail in Sec. \ref{sec:mcmc}.

\newpage

Running the MCMC program gives the following output:
\vspace*{-12pt}
{\tt \begin{Verbatim}[commandchars=\\\{\}] 
$\{MY_ANALYSIS\}/rhic% \textcolor{darkred}{\$\{MY_LOCAL\}/bin/mcmc}
At beginning of Trace, LL=-36.833322
At end of trace, best LL=-23.396510
Best Theta=
0.167961  0.115342  0.264667  0.209205  0.131394  0.155084  
Metropolis success percentage=90.640000
finished burn in
At beginning of Trace, LL=-26.849228
finished 10%
finished 20%
finished 30%
finished 40%
finished 50%
finished 60%
finished 70%
finished 80%
finished 90%
finished 100%
At end of trace, best LL=-23.262613
Best Theta=
0.178828  0.179759  0.233728  0.181965  0.185326  0.197270  
Metropolis success percentage=90.633200
writing Theta values, ntrace = 50001
writing X values, ntrace = 50001
\end{Verbatim}
}\vspace*{-12pt}
Here {\tt best LL} refers to the log-likelihood and {\tt Best Theta} refers to the value of $\vec{\theta}$ that gave the maximum log-likelihood. Values of {\tt Best Theta} and {\tt best LL} are given after the burn-in and after the trace. The ``experimental'' values were generated by running the full model with all 6 values, $\theta_i$, set to 0.2, so the fact that the best value of $\vec{\theta}$ found was close to that point is a validation of the method.

One can read the source file, {\tt \$\{MY\_LOCAL\}/software/main\_programs/mcmc\_main.cc}.

The trace is written to {\tt smooth\_data/MCMC\_trace/trace.txt}. It lists the scaled model parameters,
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
theta_1 theta_2 theta_3 theta_4 ...
theta_1 theta_2 theta_3 theta_4 ...
theta_1 theta_2 theta_3 theta_4 ...
\end{Verbatim}
}\vspace*{-12pt}
A similar file, {\tt smooth\_data/MCMC\_trace/Xtrace.txt}, shows the trace in terms of the unscaled model parameters. If {\tt MCMC\_NTRACE} is set to a million, there would be a million lines in each file. The program also calculates various covariances:
$\langle\langle\delta\theta_i\delta\theta_j\rangle\rangle$,  $\langle\langle\delta\theta_i\delta Y_a\rangle\rangle$, and $\langle\langle\delta Y_a\delta Y_b\rangle\rangle$. The quantities $\langle\langle....\rangle\rangle$ refer to averages over the  posterior, i.e. averages over the trace. The eigenvalues and eigenvectors of $\langle\langle\delta\theta_i\delta\theta_j\rangle\rangle$ are also recorded. Hopefully, the User will find the file names in {\tt mcmc\_trace/} to be self-explanatory. The files describing the posterior-weighted average, $\langle\langle \vec{\theta}\rangle\rangle$, and the posterior covariances, $\langle\langle\delta\theta_i\delta\theta_j\rangle\rangle$, are also in the directory. Other file lists the eigenvectors and eigenvalues of the covariance matrix. 

As described in Sec. \ref{sec:theory} the covariances in the posterior can also be used to quantify the resolving power of specific observables to constrain specific parameters. One such measure is
\begin{align*}\eqnumber
\mathcal{R}_{ia}&\equiv\frac{d\langle\langle\theta_i\rangle\rangle}{dY_a^{\rm exp}}\langle \delta Y_a^2\rangle^{1/2}.
\end{align*}
This quantifies how the posterior value of $\theta_i$ changes as the experimental value changes if the experimental value, $Y_a^{\rm exp}$, changes an amount characteristic of the variance of $Y_a$ across the prior. Given that there may not be a set of training points calculated uniformly across the prior, the final factor is estimated as described in Sec. \ref{sec:theory}. Higher values of $\mathcal{R}_{ia}$ for different $a$ demonstrate the relative contributions of different observables $a$ to constrain a model parameter $i$. The resolving power matrix is written to {\tt MCMC\_trace/ResolvingPower.txt}.

Hopefully, the User will find the files in this directory to be fairly self-explanatory.

\subsection{Making Plots}

\subsubsection{Setting up the Data for Plotting}

Three python scripts (using MATPLOTLIB) are provided to provide graphical insight into the posterior likelihood, into the resolving power and for viewing how the emulator uncertainty compares to the discrepancies between full-model runs (not used for tuning) and emulated values. One can visit the {\tt \$\{MY\_ANALYSIS\}/figs/} directory and peruse the file {\tt directions.pdf}, which is a copy of Sec. \ref{sec:figs} in this manual, for more detailed instructions of how to create the plots below.

First, one must create two information files. The first is {\tt \$\{MY\_ANALYSIS\}/figs/figdata/prior\_info.txt}. It differs from the one in the {\tt smooth\_data/Info/} directory in that it has only three columns, though the first columns are identical. The provided file is\\
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
   par0 gaussian ${\textbackslash}theta_0$
   par1 uniform  ${\textbackslash}theta_1$
   par2 gaussian ${\textbackslash}theta_2$
   par3 uniform  ${\textbackslash}theta_3$
   par4 gaussian ${\textbackslash}theta_4$
   par5 uniform  ${\textbackslash}theta_5$
\end{Verbatim}
}\vspace*{-12pt}
As one can see, the last column is used by MATPLOTLIB to label axes. MATPLOTLIB incorporates \LaTeX style strings, but there are some difference. For example \Verb{\r} must be \Verb{\\r} so as not to conflict with the basic file parsing. 

The second required file is {\tt \$\{MY\_ANALYSIS\}/figs/figdata/observable\_info.txt}, and the provided version is\\
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
obs0  $Y_0$
obs1  $Y_1$
obs2  $Y_2$
obs3  $Y_3$
obs4  $Y_4$
obs5  $Y_5$
obs6  $Y_6$
obs7  $Y_7$
obs8  $Y_8$
obs9  $Y_9$
\end{Verbatim}
}\vspace*{-12pt}
Again, the first column is identical to that in {\tt smooth\_data/Info/} and the second is used for labeling axes.

The two files above have already been created and placed in the {\tt figs/figdata/} directory. If the User changes the model parameters or observables, these files must both be edited to reflect the changes.

The programs also use data files created by the {\tt smoothy\_testvsfullmodel} and {\tt smoothy\_mcmc} programs. These need to be copied to a location where they can be accessed by the plotting programs.
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
$\{MY_ANALYSIS\}/rhic% \textcolor{darkred}{cp -r smooth\_data/output\_stuff/fullmodel\_testdata figs/figdata/}
$\{MY_ANALYSIS\}/rhic% \textcolor{darkred}{cp -r smooth\_data/MCMC/trace_theta.txt figs/figdata/}
$\{MY_ANALYSIS\}/rhic% \textcolor{darkred}{cp -r smooth\_data/MCMC/ResolvingPower.txt figs/figdata/}
\end{Verbatim}
}\vspace*{-12pt}

\subsubsection{Comparing Emulator Predictions at Random Points}

The first python script is in {\tt figs/YvsY/} and it compares full-model runs (not used for tuning) to the emulator. This is useful for seeing whether the emulator's error estimates are reasonable. This script plots the data written by {\tt smoothy\_testvsfullmodel}. That program created comparison files named {\tt smooth\_data/output\_stuff/fullmodel\_testdata/YvsY\_obs[0-9].txt}, which were moved to the {\tt figs/} directory with the commands above. For a specific observable, denoted by the name of the file, each of the 10 files gives a comparison of a  full-model calculation to the emulator for each of 100 randomly chosen points in model-parameter space. 

To make the plot, first change into the {\tt figs/YvsY/} directory, and enter
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
${MY_ANALYSIS}/figs/YvsY%  \textcolor{darkred}{python3 YvsY.py}
--- Observables ---
iY= 0   obs0
iY= 1   obs1
iY= 2   obs2
iY= 3   obs3
iY= 4   obs4
iY= 5   obs5
iY= 6   obs6
iY= 7   obs7
iY= 8   obs8
iY= 9   obs9
Enter iY to designate observable: \textcolor{darkred}{3}
65 of 100  points within 1 sigma
\end{Verbatim}
}\vspace*{-12pt}
The script prompts the User for which observable to consider, in this case, the User chooses 0-9 for the 10 possible observables.  The User then enters the integer {\tt iY} that corresponds to the desired observable, which for the example above was {\tt iY=3}, which is the observable named {\tt obs3}.
\begin{figure}
\centerline{\includegraphics[width=\textwidth]{figs/YvsY_tutorial.pdf}}
\caption{\label{fig:YvsY_tutorial}
Comparison of full-model values (black squares) to emulator values (red circles) for 100 points in model-parameter space. The uncertainties are solely those associated with the emulation. If the uncertainties were accurately expressed, 68\% of the points would lie within the uncertainty intervals, and in this case 65 emulator predictions were within the emulator's stated uncertainty. It is not unusual for the estimated uncertainty to be somewhat higher or lower what the User would find, even if the User were to evaluate a very large number of points.}
\end{figure}

If the User has an Apple computer, or is running Linux with the PDF viewer, {\tt okular}, the User can edit the python script and uncomment the approriate line shown in red and comment the {\tt plt.show()} and {\tt plt.close()} files. Those lines are at the end of {\tt YvsY.py},
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
 .
plt.show()
plt.close()
# if you have Mac OS and want to see pdf file, comment out previous two lines and uncomment line below
\textcolor{darkred}{#os.system("open -a Preview "+outputfilename);}
# if you have Linux and want to see pdf file, comment out previous two lines and uncomment line below
\textcolor{darkred}{#os.system("okular "+outputfilename+"&");}
 .
\end{Verbatim}
}\vspace*{-12pt}
The User can then see the actual PDF file while the script is running. Similar changes can be made to all three PYTHON plotting scripts mentioned here.

\subsubsection{Viewing the Posterior Likelihood}

To graph the posterior likelihood, first be sure to run the {\tt mcmc} program, which creates the data file {\tt smooth\_data/MCMC/trace\_theta.txt}. After moving this to the {\tt figs/figdata/} directory, one moves into the {\tt figs/posterior/} directory and enters the command:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
${MY_ANALYSIS}/figs/posterior% \textcolor{darkred}{python3 posterior.py}
\end{Verbatim}
}\vspace*{-12pt}
The script should create a figure, {\tt posterior.pdf}:
\begin{figure}
\centerline{\includegraphics[width=4.5in]{figs/posterior_tutorial.pdf}}
\caption{\label{fig:posterior_tutorial}
Projections for the posterior likelihood from the MCMC trace. The contour lines represent $1-\sigma$, $2-\sigma$ and $3-\sigma$ likelihoods.}
\end{figure}
The likelihood is projected for individual model parameters (along the diagonal), or for pairs (off-diagonal). The plot is in terms of the scaled variables, $\theta_i$. To translate to the true model-parameter ranges, one can look at the {\tt smooth\_data/Info/modelpars\_info.txt} file, which gives the prior ranges of the model parameters before they are scaled to the -1 to 1 range. The file {\tt figs/directions.pdf} shows how the User can alter the plot. For example there is a line in the python script, {\tt ParsToPlot=[1,2,3,4,5,0]}, which the User can edit to change the ordering of the model-parameters, and to choose which model parameters are considered.

\subsubsection{Viewing the Resolving Power}

Similarly, one can plot the resolving power. The data for the resolving power was also created by running {\tt smoothy\_mcmc}. The User moves the data file {\tt smooth\_data/MCMC/ResolvingPower.txt} to {\tt figs/figdata/} as mentioned above. The User then runs the PYTHON script:
\vspace*{-12pt}{\tt \begin{Verbatim}[commandchars=\\\{\}]
${MY_ANALYSIS}/figs/resolvingpower% \textcolor{darkred}{python3 RP.py}
\end{Verbatim}
}\vspace*{-12pt}
The resulting figure should look like:\\
\begin{figure}
\begin{minipage}{0.45\textwidth}
\includegraphics[width=\textwidth]{figs/RP_rhic.pdf}
\end{minipage}
\begin{minipage}{0.55\textwidth}
\caption{%\label{fig:RP_tutorial}
Resolving Power. Red bars represent positive correlations with $Y^{\rm exp}_a$ and $\theta_i$. Larger bars suggest that the particular observable contributes more to the constraint of the particular model parameter.}
\end{minipage}
\end{figure}

\end{document}
